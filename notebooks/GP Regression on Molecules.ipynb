{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213d6cca",
   "metadata": {},
   "source": [
    "# GP Regression on Molecules #\n",
    "\n",
    "An example notebook for basic GP regression on a molecular dataset. We showcase two different GP models on the Photoswitch Dataset --- one using a Tanimoto kernel applied to fingerprint representations of the molecules and another also using a Tanimoto kernel but applied to a bag-of-characters representations of molecular SMILES strings (a.k.a the bag-of-SMILES model). Towards the end of the tutorial it is shown that the GP's uncertainty estimates are correlated with prediction error and can thus act as a criteria for prioritising molecules for laboratory synthesis.\n",
    "\n",
    "Paper: https://pubs.rsc.org/en/content/articlelanding/2022/sc/d2sc04306h\n",
    "\n",
    "Code: https://github.com/Ryan-Rhys/The-Photoswitch-Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n",
    "\n",
    "# To import from the gprotorch package\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from botorch import fit_gpytorch_model\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "\n",
    "from gauche.dataloader import DataLoaderMP\n",
    "from gauche.dataloader.data_utils import transform_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5860580f",
   "metadata": {},
   "source": [
    "We define our model. See\n",
    "\n",
    "https://docs.gpytorch.ai/en/latest/examples/01_Exact_GPs/Simple_GP_Regression.html\n",
    "\n",
    "for further examples!\n",
    "\n",
    "## Defining a Molecular Kernel ##\n",
    "\n",
    "The first step is to define a Gaussian process model with a kernel that operates on molecular fingerprints (e.g. ECFP6). For this we use the Tanimoto kernel defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "k_{\\text{Tanimoto}}(\\mathbf{x}, \\mathbf{x}') = \\sigma^2_{f}\\frac{<\\mathbf{x}, \\mathbf{x}'>}{||\\mathbf{x}||^2 + ||\\mathbf{x}'||^2 \\: - <\\mathbf{x}, \\mathbf{x}'>},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{x} \\in \\mathbb{R}^D$ is a D-dimensional binary fingerprint vector i.e. components $\\mathbf{x}_i \\in \\{0, 1\\}$, $<\\cdot, \\cdot>$ is the Euclidean inner product, $||\\cdot||$ is the Euclidean norm and $\\sigma_{f}$ is a scalar kernel signal amplitude (vertical lengthscale) hyperparameter. One of the first instances of the Tanimoto kernel being used in conjunction with GP regression was in [1]. While common GP kernels that operate on continuous spaces can be applied to molecules, there is evidence to suggest that using an appropriate similarity metric for bit vectors yields improved performance [2]. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our GP model using the Tanimoto kernel\n",
    "\n",
    "from gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # We use the Tanimoto kernel to work with molecular fingerprint representations\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f34aff",
   "metadata": {},
   "source": [
    "## GP Regression on the Photoswitch Dataset ##\n",
    "\n",
    "We define our experiment parameters. In this case we are reproducing the results of the E isomer transition wavelength prediction task from https://arxiv.org/abs/2008.03226 using 20 random splits in the ratio 80/20. Note that a validation set is not necessary for GP regression since the Tanimoto kernel GP has just one trainable hyperparameter, the kernel signal amplitude! (or two if the likelihood noise is considered!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression experiments parameters, number of random splits and split size\n",
    "\n",
    "n_trials = 20\n",
    "test_set_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869a3a8",
   "metadata": {},
   "source": [
    "Load the Photoswitch Dataset via the DataLoaderMP class which contains several molecular property prediction benchmark datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Photoswitch dataset\n",
    "\n",
    "loader = DataLoaderMP()\n",
    "loader.load_benchmark(\"Photoswitch\", \"../data/property_prediction/photoswitches.csv\")\n",
    "\n",
    "# Featurise the molecules. \n",
    "\n",
    "# We use the fragprints representations (a concatenation of Morgan fingerprints and RDKit fragment features)\n",
    "\n",
    "loader.featurize('fragprints')\n",
    "X_fragprints = loader.features\n",
    "y = loader.labels\n",
    "\n",
    "# we can also consider a bag of characters summary of the molecule's SMILES string representations\n",
    "loader.load_benchmark(\"Photoswitch\", \"../data/property_prediction/photoswitches.csv\")\n",
    "loader.featurize('bag_of_smiles', max_ngram=5)\n",
    "X_boc = loader.features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d8d83b",
   "metadata": {},
   "source": [
    "## Model Evaluation ##\n",
    "\n",
    "Here we define a training/evaluation loop assessing performance using the root mean-square error (RMSE), mean average error (MAE), and $R^2$ metrics. The `evaluate_model` function also computes the GP confidence-error curve which will be explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Turn off GPyTorch warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def evaluate_model(X, y):\n",
    "    \"\"\"\n",
    "    Helper function for model evaluation\n",
    "    \n",
    "    X: Inputs\n",
    "    y: Outputs\n",
    "    \"\"\"\n",
    "\n",
    "    # initialise performance metric lists\n",
    "    r2_list = []\n",
    "    rmse_list = []\n",
    "    mae_list = []\n",
    "    \n",
    "    # We pre-allocate array for plotting confidence-error curves\n",
    "\n",
    "    _, _, _, y_test = train_test_split(X, y, test_size=test_set_size)  # To get test set size\n",
    "    n_test = len(y_test)\n",
    "\n",
    "    mae_confidence_list = np.zeros((n_trials, n_test))\n",
    "    \n",
    "    print('\\nBeginning training loop...')\n",
    "\n",
    "    for i in range(0, n_trials):\n",
    "        \n",
    "        print(f'Starting trial {i}')\n",
    "                \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n",
    "\n",
    "        #  We standardise the outputs but leave the inputs unchanged\n",
    "        _, y_train, _, y_test, y_scaler = transform_data(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n",
    "        X_train = torch.tensor(X_train.astype(np.float64))\n",
    "        X_test = torch.tensor(X_test.astype(np.float64))\n",
    "        y_train = torch.tensor(y_train).flatten()\n",
    "        y_test = torch.tensor(y_test).flatten()\n",
    "\n",
    "        # initialise GP likelihood and model\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model = ExactGPModel(X_train, y_train, likelihood)\n",
    "\n",
    "        # Find optimal model hyperparameters\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n",
    "        fit_gpytorch_model(mll)\n",
    "\n",
    "        # Get into evaluation (predictive posterior) mode\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        # mean and variance GP prediction\n",
    "        f_pred = model(X_test)\n",
    "\n",
    "        y_pred = f_pred.mean\n",
    "        y_var = f_pred.variance\n",
    "\n",
    "        # Transform back to real data space to compute metrics and detach gradients. Must unsqueeze dimension\n",
    "        # to make compatible with inverse_transform in scikit-learn version > 1\n",
    "        y_pred = y_scaler.inverse_transform(y_pred.detach().unsqueeze(dim=1))\n",
    "        y_test = y_scaler.inverse_transform(y_test.detach().unsqueeze(dim=1))\n",
    "        \n",
    "        # Compute scores for confidence curve plotting.\n",
    "\n",
    "        ranked_confidence_list = np.argsort(y_var.detach(), axis=0).flatten()\n",
    "\n",
    "        for k in range(len(y_test)):\n",
    "\n",
    "            # Construct the MAE error for each level of confidence\n",
    "\n",
    "            conf = ranked_confidence_list[0:k+1]\n",
    "            mae = mean_absolute_error(y_test[conf], y_pred[conf])\n",
    "            mae_confidence_list[i, k] = mae\n",
    "\n",
    "        # Output Standardised RMSE and RMSE on Train Set\n",
    "        y_train = y_train.detach()\n",
    "        y_pred_train = model(X_train).mean.detach()\n",
    "        train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(y_train.unsqueeze(dim=1)), \n",
    "                                                y_scaler.inverse_transform(y_pred_train.unsqueeze(dim=1))))\n",
    "\n",
    "        # Compute R^2, RMSE and MAE on Test set\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        r2_list.append(score)\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        \n",
    "    r2_list = np.array(r2_list)\n",
    "    rmse_list = np.array(rmse_list)\n",
    "    mae_list = np.array(mae_list)\n",
    "        \n",
    "    print(\"\\nmean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list)/np.sqrt(len(r2_list))))\n",
    "    print(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list)/np.sqrt(len(rmse_list))))\n",
    "    print(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list)/np.sqrt(len(mae_list)))) \n",
    "    \n",
    "    # Plot confidence-error curves\n",
    "\n",
    "    # 1e-14 instead of 0 to for numerical reasons!\n",
    "    confidence_percentiles = np.arange(1e-14, 100, 100/len(y_test))  \n",
    "\n",
    "    # We plot the Mean-absolute error confidence-error curves\n",
    "\n",
    "    mae_mean = np.mean(mae_confidence_list, axis=0)\n",
    "    mae_std = np.std(mae_confidence_list, axis=0)\n",
    "\n",
    "    mae_mean = np.flip(mae_mean)\n",
    "    mae_std = np.flip(mae_std)\n",
    "\n",
    "    # 1 sigma errorbars\n",
    "\n",
    "    lower = mae_mean - mae_std\n",
    "    upper = mae_mean + mae_std\n",
    "\n",
    "    plt.plot(confidence_percentiles, mae_mean, label='mean')\n",
    "    plt.fill_between(confidence_percentiles, lower, upper, alpha=0.2)\n",
    "    plt.xlabel('Confidence Percentile')\n",
    "    plt.ylabel('MAE (nm)')\n",
    "    plt.ylim([0, np.max(upper) + 1])\n",
    "    plt.xlim([0, 100 * ((len(y_test) - 1) / len(y_test))])\n",
    "    plt.yticks(np.arange(0, np.max(upper) + 1, 5.0))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bcaf5",
   "metadata": {},
   "source": [
    "Check the perfomance achieved by our fingerprint model. The mean RMSE should be ca. 20.9 +- 0.7 nanometres!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa469e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_fragprints, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106af6a",
   "metadata": {},
   "source": [
    "We can do the same for our bag-of-SMILES model. However, for this particular task, perfomance is a little worse at 24.8 +-0.7 nanometres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c616179",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_boc, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40654666",
   "metadata": {},
   "source": [
    "## Using the GP Uncertainty Estimates ##\n",
    "\n",
    "So far we have only considered the GP as a regressor and have not considered use-cases for the GP's uncertainty estimates. One such use-case is virtual screening applications where one would like to use model uncertainty as a criteria for prioritising molecules for synthesis; the intuition is that if two molecules have the same predicted property under the model, it will be desirable to choose the one where the model has highest confidence or equivalently lowest uncertainty. To assess whether a model's confidence is correlated with prediction error, one may plot a confidence-error curve as illustrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bd480",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"assets/confidence_curve.png\" width=\"35%\" />\n",
    "  </a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407d8e0",
   "metadata": {},
   "source": [
    "The x-axis, `Confidence Percentile`, ranks each test datapoint prediction according to the GP predictive variance. For example, molecules that reside above the 80th confidence percentile will correspond to the 20% of test set molecules with the lowest GP predictive uncertainty. The prediction error at each confidence percentile is then measured over 20 random train/test splits (the standard error over the random splits is plotted in the figure above) to gauge if the model’s confidence is correlated with the prediction error. The figure above shows that the SMILES GP's uncertainty estimates are positively correlated with the prediction error. As such, it is possible that model uncertainty could be used as a component in the decision-making process for prioritising molecules for laboratory synthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff2536",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "[1] Griffiths, R.R., Greenfield, J.L., Thawani, AR, Jamasb, A., Moss, H.B, Bourached, A., Jones, P., McCorkindale, W., Aldrick, A.A. Fuchter, M.J. and Lee, A.A., [Data-driven discovery of molecular photoswitches with multioutput Gaussian processes](https://pubs.rsc.org/en/content/articlehtml/2022/sc/d2sc04306h). Chemical Science 2022.\n",
    "\n",
    "[2] Bajusz, D., Rácz, A. and Héberger, K., 2015. [Why is Tanimoto index an appropriate choice for fingerprint-based similarity calculations?. Journal of cheminformatics](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-015-0069-3), 7(1), pp.1-13.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
