{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213d6cca",
   "metadata": {},
   "source": [
    "# Sparse GP Regression on Molecules #\n",
    "\n",
    "An example notebook for sparse GP regression to enable scalability to large molecular datasests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b75e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n",
    "\n",
    "# To import from the gauche package\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "\n",
    "from botorch import fit_gpytorch_model\n",
    "import gpytorch\n",
    "from mordred import Calculator, descriptors\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "from gauche.dataloader import DataLoaderMP\n",
    "from gauche.dataloader.data_utils import transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "856e6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our sparse GP model using and inducing point kernel wrapped around the RQ kernel\n",
    "\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, InducingPointKernel, RQKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "class SparseGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(SparseGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.base_covar_module = ScaleKernel(RQKernel())\n",
    "        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=train_x[:100, :].clone(), likelihood=likelihood)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f34aff",
   "metadata": {},
   "source": [
    "## Sparse GP Regression on the Lipophilicity Dataset ##\n",
    "\n",
    "We define our experiment parameters. In this case we are working on the large lipophilicity dataset [1] containing 4200 molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb55fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression experiments parameters, number of random splits and split size\n",
    "\n",
    "n_trials = 20\n",
    "test_set_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869a3a8",
   "metadata": {},
   "source": [
    "Load the Lipophilicity Dataset via the DataLoaderMP class which contains several molecular property prediction benchmark datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3b1f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mordred descriptor computation takes 1407.325366973877 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the Lipophilicity dataset\n",
    "\n",
    "loader = DataLoaderMP()\n",
    "loader.load_benchmark(\"Lipophilicity\", \"../data/property_prediction/lipophilicity.csv\")\n",
    "\n",
    "# Mordred descriptor computation is expensive\n",
    "calc = Calculator(descriptors, ignore_3D=False)\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in loader.features]\n",
    "t0 = time.time()\n",
    "X_mordred = [calc(mol) for mol in mols]\n",
    "t1 = time.time()\n",
    "print(f'Mordred descriptor computation takes {t1 - t0} seconds')\n",
    "X_mordred = np.array(X_mordred).astype(np.float64)\n",
    "\n",
    "\"\"\"Collect nan indices\"\"\"\n",
    "\n",
    "nan_dims = []\n",
    "\n",
    "for i in range(len(X_mordred)):\n",
    "    nan_indices = list(np.where(np.isnan(X_mordred[i, :]))[0])\n",
    "    for dim in nan_indices:\n",
    "        if dim not in nan_dims:\n",
    "            nan_dims.append(dim)\n",
    "            \n",
    "X_mordred = np.delete(X_mordred, nan_dims, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d8d83b",
   "metadata": {},
   "source": [
    "## Model Evaluation ##\n",
    "\n",
    "Here we define a training/evaluation loop assessing performance using the root mean-square error (RMSE), mean average error (MAE), and $R^2$ metrics. The `evaluate_model` function also computes the GP confidence-error curve which will be explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0826fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Turn off GPyTorch warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def evaluate_model(X, y):\n",
    "    \"\"\"Helper function for model evaluation.\n",
    "    \n",
    "    Args:\n",
    "        X: n x d NumPy array of inputs representing molecules\n",
    "        y: n x 1 NumPy array of output labels\n",
    "    Returns:\n",
    "        regression metrics and confidence-error curve plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialise performance metric lists\n",
    "    r2_list = []\n",
    "    rmse_list = []\n",
    "    mae_list = []\n",
    "    \n",
    "    # We pre-allocate array for plotting confidence-error curves\n",
    "\n",
    "    _, _, _, y_test = train_test_split(X, y, test_size=test_set_size)  # To get test set size\n",
    "    n_test = len(y_test)\n",
    "\n",
    "    mae_confidence_list = np.zeros((n_trials, n_test))\n",
    "    \n",
    "    print('\\nBeginning training loop...')\n",
    "\n",
    "    for i in range(0, n_trials):\n",
    "        \n",
    "        print(f'Starting trial {i}')\n",
    "                \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        pca_mordred = PCA(n_components=51)\n",
    "        X_train = pca_mordred.fit_transform(X_train)\n",
    "        X_test = pca_mordred.transform(X_test)\n",
    "\n",
    "        #  We standardise the outputs\n",
    "        _, y_train, _, y_test, y_scaler = transform_data(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n",
    "        X_train = torch.tensor(X_train.astype(np.float64))\n",
    "        X_test = torch.tensor(X_test.astype(np.float64))\n",
    "        y_train = torch.tensor(y_train).flatten()\n",
    "        y_test = torch.tensor(y_test).flatten()\n",
    "\n",
    "        # initialise GP likelihood and model\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model = SparseGPModel(X_train, y_train, likelihood)\n",
    "\n",
    "        # Find optimal model hyperparameters\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n",
    "        fit_gpytorch_model(mll)\n",
    "\n",
    "        # Get into evaluation (predictive posterior) mode\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        # mean and variance GP prediction\n",
    "        f_pred = model(X_test)\n",
    "\n",
    "        y_pred = f_pred.mean\n",
    "        y_var = f_pred.variance\n",
    "\n",
    "        # Transform back to real data space to compute metrics and detach gradients. Must unsqueeze dimension\n",
    "        # to make compatible with inverse_transform in scikit-learn version > 1\n",
    "        y_pred = y_scaler.inverse_transform(y_pred.detach().unsqueeze(dim=1))\n",
    "        y_test = y_scaler.inverse_transform(y_test.detach().unsqueeze(dim=1))\n",
    "        \n",
    "        # Compute scores for confidence curve plotting.\n",
    "\n",
    "        ranked_confidence_list = np.argsort(y_var.detach(), axis=0).flatten()\n",
    "\n",
    "        for k in range(len(y_test)):\n",
    "\n",
    "            # Construct the MAE error for each level of confidence\n",
    "\n",
    "            conf = ranked_confidence_list[0:k+1]\n",
    "            mae = mean_absolute_error(y_test[conf], y_pred[conf])\n",
    "            mae_confidence_list[i, k] = mae\n",
    "\n",
    "        # Output Standardised RMSE and RMSE on Train Set\n",
    "        y_train = y_train.detach()\n",
    "        y_pred_train = model(X_train).mean.detach()\n",
    "        train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(y_train.unsqueeze(dim=1)), \n",
    "                                                y_scaler.inverse_transform(y_pred_train.unsqueeze(dim=1))))\n",
    "\n",
    "        # Compute R^2, RMSE and MAE on Test set\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        r2_list.append(score)\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        \n",
    "    r2_list = np.array(r2_list)\n",
    "    rmse_list = np.array(rmse_list)\n",
    "    mae_list = np.array(mae_list)\n",
    "        \n",
    "    print(\"\\nmean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list)/np.sqrt(len(r2_list))))\n",
    "    print(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list)/np.sqrt(len(rmse_list))))\n",
    "    print(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list)/np.sqrt(len(mae_list)))) \n",
    "    \n",
    "    # Plot confidence-error curves\n",
    "\n",
    "    # 1e-14 instead of 0 to for numerical reasons!\n",
    "    confidence_percentiles = np.arange(1e-14, 100, 100/len(y_test))  \n",
    "\n",
    "    # We plot the Mean-absolute error confidence-error curves\n",
    "\n",
    "    mae_mean = np.mean(mae_confidence_list, axis=0)\n",
    "    mae_std = np.std(mae_confidence_list, axis=0)\n",
    "\n",
    "    mae_mean = np.flip(mae_mean)\n",
    "    mae_std = np.flip(mae_std)\n",
    "\n",
    "    # 1 sigma errorbars\n",
    "\n",
    "    lower = mae_mean - mae_std\n",
    "    upper = mae_mean + mae_std\n",
    "\n",
    "    plt.plot(confidence_percentiles, mae_mean, label='mean')\n",
    "    plt.fill_between(confidence_percentiles, lower, upper, alpha=0.2)\n",
    "    plt.xlabel('Confidence Percentile')\n",
    "    plt.ylabel('MAE (nm)')\n",
    "    plt.ylim([0, np.max(upper) + 1])\n",
    "    plt.xlim([0, 100 * ((len(y_test) - 1) / len(y_test))])\n",
    "    plt.yticks(np.arange(0, np.max(upper) + 1, 5.0))\n",
    "    plt.show()\n",
    "    \n",
    "    return rmse_list, mae_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bcaf5",
   "metadata": {},
   "source": [
    "Check the perfomance achieved by our sparse GP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa469e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning training loop...\n",
      "Starting trial 0\n",
      "Starting trial 1\n",
      "Starting trial 2\n",
      "Starting trial 3\n",
      "Starting trial 4\n",
      "Starting trial 5\n",
      "Starting trial 6\n",
      "Starting trial 7\n",
      "Starting trial 8\n",
      "Starting trial 9\n",
      "Starting trial 10\n",
      "Starting trial 11\n",
      "Starting trial 12\n",
      "Starting trial 13\n",
      "Starting trial 14\n",
      "Starting trial 15\n",
      "Starting trial 16\n",
      "Starting trial 17\n",
      "Starting trial 18\n",
      "Starting trial 19\n",
      "\n",
      "mean R^2: 0.3715 +- 0.0443\n",
      "mean RMSE: 0.9370 +- 0.0299\n",
      "mean MAE: 0.7444 +- 0.0255\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_mordred, mae_mordred = evaluate_model(X_mordred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff2536",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "[1] Anna Gaulton, Louisa J Bellis, A Patricia Bento, Jon Chambers, Mark Davies, Anne Hersey,\n",
    "Yvonne Light, Shaun McGlinchey, David Michalovich, Bissan Al-Lazikani, et al. [ChEMBL:\n",
    "A large-scale bioactivity database for drug discovery](https://pubmed.ncbi.nlm.nih.gov/21948594/). Nucleic Acids Research, 2012.\n",
    "\n",
    "[2] Bajusz, D., Rácz, A. and Héberger, K., 2015. [Why is Tanimoto index an appropriate choice for fingerprint-based similarity calculations?. Journal of cheminformatics](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-015-0069-3), 7(1), pp.1-13."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
