{
  "index": [],
  "modules/dataloader": [],
  "modules/kernels": [
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(BraunBlanquetKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(BraunBlanquetKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(DiceKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(DiceKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(FaithKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(FaithKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(ForbesKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(ForbesKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(InnerProductKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(InnerProductKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(IntersectionKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(IntersectionKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(MinMaxKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(MinMaxKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(OtsukaKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(OtsukaKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(RandKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(RandKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(RogersTanimotoKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(RogersTanimotoKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(RusselRaoKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(RusselRaoKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(SogenfreiKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(SogenfreiKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": ">>> x = torch.randint(0, 2, (10, 5))\n>>> # Non-batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(SokalSneathKernel())\n>>> covar = covar_module(x)  # Output: LazyTensor of size (10 x 10)\n>>>\n>>> batch_x = torch.randint(0, 2, (2, 10, 5))\n>>> # Batch: Simple option\n>>> covar_module = gpytorch.kernels.ScaleKernel(SokalSneathKernel())\n>>> covar = covar_module(batch_x)  # Output: LazyTensor of size (2 x 10 x 10)",
      "names": [],
      "example": {
        "document": "modules/kernels",
        "ref_id": "module-gauche.kernels.fingerprint_kernels.tanimoto_kernel",
        "headings": [
          "gauche.kernels",
          "Fingerprint Kernels"
        ]
      },
      "doc_lineno": null
    }
  ],
  "modules/representations": [],
  "notebooks/bayesian_gnn_on_molecules": [
    {
      "source": "# install gauche and other dependencies\n\n%%capture\n!pip install gauche[graphs] bayesian-torch torch_geometric",
      "names": [],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Install-and-import-dependencies",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Install and import dependencies"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import os, sys\nsys.path.append('..')\nfrom tqdm import tqdm\nimport copy\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# import sklearn\nfrom gauche.dataloader import MolPropLoader\nfrom gauche.dataloader.data_utils import transform_data\n\nimport pandas as pd\nimport numpy as np\nimport rdkit.Chem.AllChem as Chem\nimport matplotlib.pyplot as plt\n\nfrom scipy.stats import norm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import MessagePassing, global_mean_pool\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.utils import add_self_loops\nfrom bayesian_torch.layers import LinearFlipout, LinearReparameterization",
      "names": [
        {
          "import_components": [
            "os"
          ],
          "code_str": "os",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "os"
        },
        {
          "import_components": [
            "sys"
          ],
          "code_str": "sys",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "sys"
        },
        {
          "import_components": [
            "copy"
          ],
          "code_str": "copy",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "copy"
        },
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils"
          ],
          "code_str": "gauche.dataloader.data_utils",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_from",
          "resolved_location": "gauche.dataloader.data_utils"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 16,
          "end_lineno": 16,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "scipy",
            "stats"
          ],
          "code_str": "scipy.stats",
          "lineno": 18,
          "end_lineno": 18,
          "context": "import_from",
          "resolved_location": "scipy.stats"
        },
        {
          "import_components": [
            "scipy",
            "stats",
            "norm"
          ],
          "code_str": "norm",
          "lineno": 18,
          "end_lineno": 18,
          "context": "import_target",
          "resolved_location": "scipy.stats.norm"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "sklearn",
            "metrics"
          ],
          "code_str": "sklearn.metrics",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_from",
          "resolved_location": "sklearn.metrics"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 23,
          "end_lineno": 23,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "torch",
            "nn"
          ],
          "code_str": "torch.nn",
          "lineno": 24,
          "end_lineno": 24,
          "context": "import_target",
          "resolved_location": "torch.nn"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Install-and-import-dependencies",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Install and import dependencies"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# define a custom PyTorch Geometric featuriser that captures\n# element number, bond types and chirality\n\nallowable_features = {\n    \"possible_atomic_num_list\": list(range(1, 119)),\n    \"possible_chirality_list\": [\n        Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n        Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n        Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n        Chem.rdchem.ChiralType.CHI_OTHER,\n    ],\n    \"possible_bonds\": [\n        Chem.rdchem.BondType.SINGLE,\n        Chem.rdchem.BondType.DOUBLE,\n        Chem.rdchem.BondType.TRIPLE,\n        Chem.rdchem.BondType.AROMATIC,\n    ],\n    # (E)/(Z) double bond stereo information\n    \"possible_bond_dirs\": [\n        Chem.rdchem.BondDir.NONE,\n        Chem.rdchem.BondDir.ENDUPRIGHT,\n        Chem.rdchem.BondDir.ENDDOWNRIGHT,\n    ],\n}\n\n# define constants for featurisation and embedding\nnum_atom_type = 120  # including the extra mask tokens\nnum_chirality_tag = 3\nnum_bond_type = 6  # including aromatic and self-loop edge, and extra masked tokens\nnum_bond_direction = 3\nself_loop_token = 4  # bond type for self-loop edge\nmasked_bond_token = 5  # bond type for masked edges\n\n\ndef mol_to_pyg(smiles):\n    \"\"\"\n    A featuriser that accepts an smiles STRING and\n    converts it to a PyTorch Geometric data object that\n    is compatible with the GNN modules below.\n    Args:\n        smiles: SMILES string\n    Returns: PyTorch Geometric data object\n    \"\"\"\n\n    mol = Chem.MolFromSmiles(smiles)\n\n    # derive atom features: atomic number + chirality tag\n    atom_features = []\n    for atom in mol.GetAtoms():\n        atom_features.append(\n            [\n                allowable_features[\"possible_atomic_num_list\"].index(\n                    atom.GetAtomicNum()\n                ),\n                allowable_features[\"possible_chirality_list\"].index(\n                    atom.GetChiralTag()\n                ),\n            ]\n        )\n    atom_features = torch.tensor(np.array(atom_features), dtype=torch.long)\n\n    # derive bond features: bond type + bond direction\n    # PyTorch Geometric only uses directed edges,\n    # so feature information needs to be added twice\n    edge_index = []\n    edge_attr = []\n    for bond in mol.GetBonds():\n        i = bond.GetBeginAtomIdx()\n        j = bond.GetEndAtomIdx()\n        edge_index.append((i, j))\n        edge_index.append((j, i))\n\n        # calculate edge features and append them to feature list\n        edge_feature = [\n            allowable_features[\"possible_bonds\"].index(bond.GetBondType()),\n            allowable_features[\"possible_bond_dirs\"].index(bond.GetBondDir()),\n        ]\n        edge_attr.append(edge_feature)\n        edge_attr.append(edge_feature)\n\n    # set data.edge_index: Graph connectivity in COO format with shape [2, num_edges]\n    edge_index = torch.tensor(np.array(edge_index).T, dtype=torch.long)\n\n    # set data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n    edge_attr = torch.tensor(np.array(edge_attr), dtype=torch.long)\n\n    return Data(x=atom_features, edge_index=edge_index, edge_attr=edge_attr)",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 60,
          "end_lineno": 60,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 60,
          "end_lineno": 60,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 82,
          "end_lineno": 82,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 82,
          "end_lineno": 82,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 85,
          "end_lineno": 85,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 85,
          "end_lineno": 85,
          "context": "none",
          "resolved_location": "torch.tensor"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Featurise-Molecules-and-PyTorch-Geometric-Graphs",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Featurise Molecules and PyTorch Geometric Graphs"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# load PhotoSwitch dataset and apply mol_to_pyg featuriser\n\ndataset = \"Photoswitch\"\n\nloader = MolPropLoader()\nloader.load_benchmark(\"Photoswitch\")\nloader.featurize(lambda smiles: [mol_to_pyg(s) for s in smiles])",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.featurize"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Featurise-Molecules-and-PyTorch-Geometric-Graphs",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Featurise Molecules and PyTorch Geometric Graphs"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class GINConv(MessagePassing):\n    \"\"\"\n    Extension of the Graph Isomorphism Network to incorporate\n    edge information by concatenating edge embeddings.\n    \"\"\"\n\n    def __init__(self, emb_dim, aggr=\"add\"):\n        \"\"\"\n        Initialise GIN convolutional layer.\n        Args:\n            emb_dim: latent node embedding dimension\n            aggr: aggregation procedure\n        \"\"\"\n        super(GINConv, self).__init__()\n\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(emb_dim, 2 * emb_dim),\n            torch.nn.ReLU(),\n            torch.nn.Linear(2 * emb_dim, emb_dim),\n        )\n\n        self.edge_embedding1 = torch.nn.Embedding(num_bond_type, emb_dim)\n        self.edge_embedding2 = torch.nn.Embedding(num_bond_direction, emb_dim)\n        torch.nn.init.xavier_uniform_(self.edge_embedding1.weight.data)\n        torch.nn.init.xavier_uniform_(self.edge_embedding2.weight.data)\n\n        self.aggr = aggr\n\n    def forward(self, x, edge_index, edge_attr):\n        \"\"\"\n        Message passing and aggregation function\n        of the adapted GIN convolutional layer.\n        Args:\n            x: node features\n            edge_index: adjacency list\n            edge_attr: edge features\n        Returns: transformed and aggregated node embeddings\n        \"\"\"\n\n        # add self loops to edge index\n        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n\n        # update edge attributes to represent self-loop edges\n        self_loop_attr = torch.zeros(x.size(0), 2)\n        self_loop_attr[:, 0] = self_loop_token\n        self_loop_attr = self_loop_attr.to(edge_attr.device).to(\n            edge_attr.dtype\n        )\n        edge_attr = torch.cat((edge_attr, self_loop_attr), dim=0)\n\n        # generate edge embeddings and propagate\n        edge_embeddings = self.edge_embedding1(\n            edge_attr[:, 0]\n        ) + self.edge_embedding2(edge_attr[:, 1])\n        return self.propagate(edge_index, x=x, edge_attr=edge_embeddings)\n\n    def message(self, x_j, edge_attr):\n        return x_j + edge_attr\n\n    def update(self, aggr_out):\n        return self.mlp(aggr_out)\n\n\nclass GNN(torch.nn.Module):\n    \"\"\"\n    Combine multiple GNN layers into a network.\n    \"\"\"\n\n    def __init__(self, num_layers=5, embed_dim=300, gnn_type=\"gin\"):\n        \"\"\"\n        Compose convolution layers into GNN. Pretrained parameters\n        exist for a 5-layer network with 300 hidden units.\n        Args:\n            num_layers: number of convolution layers\n            embed_dim: dimension of node embeddings\n            gnn_type: type of convolutional layer to use\n        \"\"\"\n\n        self.num_layers = num_layers\n        self.embed_dim = embed_dim\n        self.gnn_type = gnn_type\n\n        super(GNN, self).__init__()\n\n        # initialise label embeddings\n        self.x_embedding1 = torch.nn.Embedding(num_atom_type, self.embed_dim)\n        self.x_embedding2 = torch.nn.Embedding(\n            num_chirality_tag, self.embed_dim\n        )\n        torch.nn.init.xavier_uniform_(self.x_embedding1.weight.data)\n        torch.nn.init.xavier_uniform_(self.x_embedding2.weight.data)\n\n        # initialise GNN layers\n        self.gnns = torch.nn.ModuleList()\n        for layer in range(self.num_layers):\n            if gnn_type == \"gin\":\n                self.gnns.append(GINConv(emb_dim=self.embed_dim))\n            else:\n                raise NotImplementedError(\"Invalid GNN layer type.\")\n\n        # initialise BatchNorm layers\n        self.batch_norms = torch.nn.ModuleList()\n        for layer in range(self.num_layers):\n            self.batch_norms.append(torch.nn.BatchNorm1d(self.embed_dim))\n\n    def forward(self, x, edge_index, edge_attr):\n        \"\"\"\n        Forward function of the GNN class that takes a PyTorch geometric\n        representation of a molecule or a batch of molecules\n        and generates the node embeddings for each atom.\n        Args:\n            x: node features\n            edge_index: adjacency list\n            edge_attr: edge features\n        Returns: tensor of num_nodes x embedding_dim embeddings\n        \"\"\"\n\n        # x[:, 0] corresponds to 'possible_atomic_num_list',\n        # x[:, 1] corresponds to 'possible_chirality_list'\n        x = self.x_embedding1(x[:, 0]) + self.x_embedding2(x[:, 1])\n\n        for layer in range(self.num_layers):\n            # x are atom features of the molecule and edge_attr the atomic features of the molecule\n            x = self.gnns[layer](x, edge_index, edge_attr)\n            x = self.batch_norms[layer](x)\n            if layer != self.num_layers - 1:\n                x = F.relu(x)\n\n        return x",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "Linear"
          ],
          "code_str": "torch.nn.Linear",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "torch.nn.modules.linear.Linear"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "ReLU"
          ],
          "code_str": "torch.nn.ReLU",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "torch.nn.modules.activation.ReLU"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "Linear"
          ],
          "code_str": "torch.nn.Linear",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "torch.nn.modules.linear.Linear"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "Sequential"
          ],
          "code_str": "torch.nn.Sequential",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "torch.nn.modules.container.Sequential"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "Embedding"
          ],
          "code_str": "torch.nn.Embedding",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "torch.nn.modules.sparse.Embedding"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "Embedding"
          ],
          "code_str": "torch.nn.Embedding",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "torch.nn.modules.sparse.Embedding"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "init",
            "xavier_uniform_"
          ],
          "code_str": "torch.nn.init.xavier_uniform_",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "torch.nn.init.xavier_uniform_"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "init",
            "xavier_uniform_"
          ],
          "code_str": "torch.nn.init.xavier_uniform_",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "torch.nn.init.xavier_uniform_"
        },
        {
          "import_components": [
            "torch",
            "zeros"
          ],
          "code_str": "torch.zeros",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "torch.zeros"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 49,
          "end_lineno": 49,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "Module"
          ],
          "code_str": "torch.nn.Module",
          "lineno": 64,
          "end_lineno": 64,
          "context": "none",
          "resolved_location": "torch.nn.modules.module.Module"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 83,
          "end_lineno": 83,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "Embedding"
          ],
          "code_str": "torch.nn.Embedding",
          "lineno": 86,
          "end_lineno": 86,
          "context": "none",
          "resolved_location": "torch.nn.modules.sparse.Embedding"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "Embedding"
          ],
          "code_str": "torch.nn.Embedding",
          "lineno": 87,
          "end_lineno": 87,
          "context": "none",
          "resolved_location": "torch.nn.modules.sparse.Embedding"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "init",
            "xavier_uniform_"
          ],
          "code_str": "torch.nn.init.xavier_uniform_",
          "lineno": 90,
          "end_lineno": 90,
          "context": "none",
          "resolved_location": "torch.nn.init.xavier_uniform_"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "init",
            "xavier_uniform_"
          ],
          "code_str": "torch.nn.init.xavier_uniform_",
          "lineno": 91,
          "end_lineno": 91,
          "context": "none",
          "resolved_location": "torch.nn.init.xavier_uniform_"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "ModuleList"
          ],
          "code_str": "torch.nn.ModuleList",
          "lineno": 94,
          "end_lineno": 94,
          "context": "none",
          "resolved_location": "torch.nn.modules.container.ModuleList"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 95,
          "end_lineno": 95,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "NotImplementedError"
          ],
          "code_str": "NotImplementedError",
          "lineno": 99,
          "end_lineno": 99,
          "context": "none",
          "resolved_location": "NotImplementedError"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "ModuleList"
          ],
          "code_str": "torch.nn.ModuleList",
          "lineno": 102,
          "end_lineno": 102,
          "context": "none",
          "resolved_location": "torch.nn.modules.container.ModuleList"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 103,
          "end_lineno": 103,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "BatchNorm1d"
          ],
          "code_str": "torch.nn.BatchNorm1d",
          "lineno": 104,
          "end_lineno": 104,
          "context": "none",
          "resolved_location": "torch.nn.modules.batchnorm.BatchNorm1d"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 122,
          "end_lineno": 122,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "functional",
            "relu"
          ],
          "code_str": "F.relu",
          "lineno": 127,
          "end_lineno": 127,
          "context": "none",
          "resolved_location": "torch.nn.functional.relu"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "functional",
            "relu",
            "()"
          ],
          "code_str": "x",
          "lineno": 127,
          "end_lineno": 127,
          "context": "none",
          "resolved_location": "torch.Tensor"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "functional",
            "relu",
            "()"
          ],
          "code_str": "x",
          "lineno": 129,
          "end_lineno": 129,
          "context": "none",
          "resolved_location": "torch.Tensor"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Define-GIN-Layers-and-GNN",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Define GIN Layers and GNN"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "class BayesianGNN(nn.Module):\n    def __init__(self, embed_dim=300, num_layers=5, gnn_type='gin', output_dim=1):\n        super().__init__()\n        self.gnn = GNN(num_layers=num_layers, embed_dim=embed_dim, gnn_type=gnn_type)\n        self.pooling = global_mean_pool\n        self.bayes_layer = LinearReparameterization(embed_dim, output_dim)\n\n    def forward(self, data):\n        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n        res = self.gnn(x, edge_index, edge_attr)\n        res = self.pooling(res, batch)\n\n        # bayesian layer\n        kl_sum = 0\n        res, kl = self.bayes_layer(res)\n        kl_sum += kl\n        return res, kl_sum",
      "names": [
        {
          "import_components": [
            "torch",
            "nn",
            "Module"
          ],
          "code_str": "nn.Module",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "torch.nn.modules.module.Module"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Construct-the-Bayesian-GNN-module-and-define-the-training-and-evaluation-protocol",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Construct the Bayesian GNN module and define the training and evaluation protocol"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def nlpd(y, y_pred, y_std):\n    nld = 0\n    for y_true, mu, std in zip(y.ravel(), y_pred.ravel(), y_std.ravel()):\n        nld  += -norm(mu, std).logpdf(y_true)\n    return nld / len(y)\n\ndef predict(regressor, X, samples = 100):\n    preds = [regressor(X)[0] for i in range(samples)]\n    preds = torch.stack(preds)\n    means = preds.mean(axis=0)\n    var = preds.var(axis=0)\n    return means, var\n\ndef graph_append_label(X, y, device):\n    G = []\n    for g, label in zip(X, y):\n        g.y = label\n        g = g.to(device)\n        G.append(g)\n    return G",
      "names": [
        {
          "import_components": [
            "zip"
          ],
          "code_str": "zip",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "zip"
        },
        {
          "import_components": [
            "scipy",
            "stats",
            "norm"
          ],
          "code_str": "norm",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "scipy.stats.norm"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "torch",
            "stack"
          ],
          "code_str": "torch.stack",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "torch.stack"
        },
        {
          "import_components": [
            "zip"
          ],
          "code_str": "zip",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "zip"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Construct-the-Bayesian-GNN-module-and-define-the-training-and-evaluation-protocol",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Construct the Bayesian GNN module and define the training and evaluation protocol"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def evaluate_model(X, y, n_epochs=100, n_trials=20, kld_beta = 1., verbose=True):\n    test_set_size = 0.2\n    batch_size = 32\n\n    r2_list = []\n    rmse_list = []\n    mae_list = []\n    nlpd_list = []\n\n    # We pre-allocate array for plotting confidence-error curves\n\n    _, y_test = train_test_split(y, test_size=test_set_size)  # To get test set size\n    n_test = len(y_test)\n\n    mae_confidence_list = np.zeros((n_trials, n_test))\n\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    print(f'Device being used: {device}')\n\n    print('\\nBeginning training loop...')\n\n    for i in range(0, n_trials):\n\n        print(f'Starting trial {i}')\n\n        # split data and perform standardization\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n        _, y_train, _, y_test, y_scaler = transform_data(y_train, y_train, y_test, y_test)\n\n        # include y in the pyg graph structure\n        G_train = graph_append_label(X_train, y_train, device)\n        G_test = graph_append_label(X_test, y_test, device)\n\n        dataloader_train = DataLoader(G_train, batch_size=batch_size, shuffle=True, drop_last=True)\n        dataloader_test = DataLoader(G_test, batch_size=len(G_test))\n\n        # initialize model and optimizer\n        model = BayesianGNN(gnn_type='gin').to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n        criterion = torch.nn.MSELoss()\n\n        training_loss = []\n\n        status = {}\n        best_loss = np.inf\n        patience = 50\n        count = 0\n        pbar = tqdm(range(n_epochs))\n        for epoch in pbar:\n            running_kld_loss = 0\n            running_mse_loss = 0\n            running_loss = 0\n            for data in dataloader_train:\n                optimizer.zero_grad()\n\n                output, kl = model(data)\n\n                # calculate loss with kl term for Bayesian layers\n                target = torch.tensor(np.array(data.y), dtype=torch.float, device=device)\n                mse_loss = criterion(output, target)\n                loss = mse_loss + kl * kld_beta / batch_size\n\n                loss.backward()\n                optimizer.step()\n\n                running_mse_loss += mse_loss.detach().cpu().numpy()\n                running_kld_loss += kl.detach().cpu().numpy()\n                running_loss += loss.detach().cpu().numpy()\n\n            status.update({\n                'Epoch': epoch,\n                'loss': running_loss/len(dataloader_train),\n                'kl': running_kld_loss/len(dataloader_train),\n                'mse': running_mse_loss/len(dataloader_train)\n            })\n            training_loss.append(status)\n            pbar.set_postfix(status)\n\n            with torch.no_grad():\n                for data in dataloader_test:\n                    y_pred, y_var = predict(model, data)\n                    target = torch.tensor(np.array(data.y), dtype=torch.float, device=device)\n                    val_loss = criterion(y_pred, target)\n                    val_loss = val_loss.detach().cpu().numpy()\n                    status.update({'val_loss': val_loss})\n\n                if best_loss > val_loss:\n                    best_loss = val_loss\n                    best_model = copy.deepcopy(model)\n                    count = 0\n                else:\n                    count += 1\n\n                if count >= patience:\n                    if verbose: print(f'Early stopping reached! Best validation loss {best_loss}')\n                    break\n\n            pbar.set_postfix(status)\n\n        # Get into evaluation (predictive posterior) mode\n        model = best_model\n        model.eval()\n\n        with torch.no_grad():\n            # mean and variance by sampling\n            for data in dataloader_test:\n                y_pred, y_var = predict(model, data, samples=100)\n                y_pred = y_pred.detach().cpu().numpy()\n                y_var = y_var.detach().cpu().numpy()\n\n        uq_nlpd = nlpd(y_test, y_pred, np.sqrt(y_var))\n        if verbose: print(f'NLPD: {uq_nlpd}')\n\n        # Transform back to real data space to compute metrics and detach gradients.\n        y_pred = y_scaler.inverse_transform(y_pred)\n        y_test = y_scaler.inverse_transform(y_test)\n\n        # Compute scores for confidence curve plotting.\n        ranked_confidence_list = np.argsort(y_var, axis=0).flatten()\n\n        for k in range(len(y_test)):\n\n            # Construct the MAE error for each level of confidence\n            conf = ranked_confidence_list[0:k+1]\n            mae = mean_absolute_error(y_test[conf], y_pred[conf])\n            mae_confidence_list[i, k] = mae\n\n        # Compute R^2, RMSE and MAE on Test set\n        score = r2_score(y_test, y_pred)\n        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n        mae = mean_absolute_error(y_test, y_pred)\n\n        r2_list.append(score)\n        rmse_list.append(rmse)\n        mae_list.append(mae)\n        nlpd_list.append(uq_nlpd)\n\n    r2_list = np.array(r2_list)\n    rmse_list = np.array(rmse_list)\n    mae_list = np.array(mae_list)\n    nlpd_list = np.array(nlpd_list)\n\n    print(\"\\nmean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list)/np.sqrt(len(r2_list))))\n    print(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list)/np.sqrt(len(rmse_list))))\n    print(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list)/np.sqrt(len(mae_list))))\n    print(\"mean NLPD: {:.4f} +- {:.4f}\\n\".format(np.mean(nlpd_list), np.std(nlpd_list)/np.sqrt(len(nlpd_list))))\n    print()\n\n    # Plot confidence-error curves\n\n    # 1e-14 instead of 0 to for numerical reasons!\n    confidence_percentiles = np.arange(1e-14, 100, 100/len(y_test))\n\n    # We plot the Mean-absolute error confidence-error curves\n\n    mae_mean = np.mean(mae_confidence_list, axis=0)\n    mae_std = np.std(mae_confidence_list, axis=0)\n\n    mae_mean = np.flip(mae_mean)\n    mae_std = np.flip(mae_std)\n\n    # 1 sigma errorbars\n\n    lower = mae_mean - mae_std\n    upper = mae_mean + mae_std\n\n    fig = plt.figure()\n    plt.plot(confidence_percentiles, mae_mean, label='mean')\n    plt.fill_between(confidence_percentiles, lower, upper, alpha=0.2)\n    plt.xlabel('Confidence Percentile')\n    plt.ylabel('MAE')\n    plt.ylim([0, np.max(upper) + 1])\n    plt.xlim([0, 100 * ((len(y_test) - 1) / len(y_test))])\n\n    results = {\n        'confidence_percentiles': confidence_percentiles,\n        'mae_mean': mae_mean,\n        'mae_std': mae_std,\n        'mae': mae_list,\n        'rmse': rmse_list,\n        'r2': r2_list,\n        'nlpd': nlpd_list,\n    }\n\n    return results, fig",
      "names": [
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "torch",
            "cuda",
            "is_available"
          ],
          "code_str": "torch.cuda.is_available",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "torch.cuda.is_available"
        },
        {
          "import_components": [
            "torch",
            "device"
          ],
          "code_str": "torch.device",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "torch.device"
        },
        {
          "import_components": [
            "torch",
            "device"
          ],
          "code_str": "torch.device",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "torch.device"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "torch",
            "optim",
            "Adam"
          ],
          "code_str": "torch.optim.Adam",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "torch.optim.adam.Adam"
        },
        {
          "import_components": [
            "torch",
            "optim",
            "Adam",
            "()"
          ],
          "code_str": "optimizer",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "torch.optim.adam.Adam"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "MSELoss"
          ],
          "code_str": "torch.nn.MSELoss",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "torch.nn.modules.loss.MSELoss"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "MSELoss",
            "()"
          ],
          "code_str": "criterion",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "torch.nn.modules.loss.MSELoss"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "np.inf",
          "lineno": 45,
          "end_lineno": 45,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "best_loss",
          "lineno": 45,
          "end_lineno": 45,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 48,
          "end_lineno": 48,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 59,
          "end_lineno": 59,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 59,
          "end_lineno": 59,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "MSELoss",
            "()"
          ],
          "code_str": "criterion",
          "lineno": 60,
          "end_lineno": 60,
          "context": "none",
          "resolved_location": "torch.nn.modules.loss.MSELoss"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 72,
          "end_lineno": 72,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 73,
          "end_lineno": 73,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 74,
          "end_lineno": 74,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "torch",
            "no_grad"
          ],
          "code_str": "torch.no_grad",
          "lineno": 79,
          "end_lineno": 79,
          "context": "none",
          "resolved_location": "torch.autograd.grad_mode.no_grad"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 82,
          "end_lineno": 82,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 82,
          "end_lineno": 82,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "nn",
            "MSELoss",
            "()"
          ],
          "code_str": "criterion",
          "lineno": 83,
          "end_lineno": 83,
          "context": "none",
          "resolved_location": "torch.nn.modules.loss.MSELoss"
        },
        {
          "import_components": [
            "numpy",
            "inf"
          ],
          "code_str": "best_loss",
          "lineno": 87,
          "end_lineno": 87,
          "context": "none",
          "resolved_location": "numpy.inf"
        },
        {
          "import_components": [
            "copy",
            "deepcopy"
          ],
          "code_str": "copy.deepcopy",
          "lineno": 89,
          "end_lineno": 89,
          "context": "none",
          "resolved_location": "copy.deepcopy"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 95,
          "end_lineno": 95,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "torch",
            "no_grad"
          ],
          "code_str": "torch.no_grad",
          "lineno": 104,
          "end_lineno": 104,
          "context": "none",
          "resolved_location": "torch.autograd.grad_mode.no_grad"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 111,
          "end_lineno": 111,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 112,
          "end_lineno": 112,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "argsort"
          ],
          "code_str": "np.argsort",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "numpy.argsort"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 121,
          "end_lineno": 121,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 121,
          "end_lineno": 121,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 125,
          "end_lineno": 125,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 129,
          "end_lineno": 129,
          "context": "none",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 130,
          "end_lineno": 130,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 130,
          "end_lineno": 130,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 131,
          "end_lineno": 131,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 138,
          "end_lineno": 138,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 139,
          "end_lineno": 139,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 140,
          "end_lineno": 140,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 141,
          "end_lineno": 141,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 143,
          "end_lineno": 143,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 143,
          "end_lineno": 143,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 143,
          "end_lineno": 143,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 143,
          "end_lineno": 143,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 143,
          "end_lineno": 143,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 146,
          "end_lineno": 146,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 146,
          "end_lineno": 146,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 146,
          "end_lineno": 146,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 146,
          "end_lineno": 146,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 146,
          "end_lineno": 146,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 147,
          "end_lineno": 147,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 152,
          "end_lineno": 152,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 152,
          "end_lineno": 152,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 156,
          "end_lineno": 156,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 157,
          "end_lineno": 157,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 159,
          "end_lineno": 159,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 160,
          "end_lineno": 160,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 167,
          "end_lineno": 167,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure",
            "()"
          ],
          "code_str": "fig",
          "lineno": 167,
          "end_lineno": 167,
          "context": "none",
          "resolved_location": "matplotlib.figure.Figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 168,
          "end_lineno": 168,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "fill_between"
          ],
          "code_str": "plt.fill_between",
          "lineno": 169,
          "end_lineno": 169,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.fill_between"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 170,
          "end_lineno": 170,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 171,
          "end_lineno": 171,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 172,
          "end_lineno": 172,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 172,
          "end_lineno": 172,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 173,
          "end_lineno": 173,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 173,
          "end_lineno": 173,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 173,
          "end_lineno": 173,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure",
            "()"
          ],
          "code_str": "fig",
          "lineno": 185,
          "end_lineno": 185,
          "context": "none",
          "resolved_location": "matplotlib.figure.Figure"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Construct-the-Bayesian-GNN-module-and-define-the-training-and-evaluation-protocol",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Construct the Bayesian GNN module and define the training and evaluation protocol"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "results, fig = evaluate_model(loader.features, loader.labels, n_epochs=300, n_trials=10, kld_beta=50.0)\nfig.show()",
      "names": [],
      "example": {
        "document": "notebooks/bayesian_gnn_on_molecules",
        "ref_id": "Run-the-training-and-evaluation-loop",
        "headings": [
          "Bayesian GNNs for Molecular Property Prediction",
          "Run the training and evaluation loop"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/bayesian_optimisation_over_molecules": [
    {
      "source": "\"\"\"Imports.\"\"\"\n\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimport numpy as np\nimport torch\nfrom botorch import fit_gpytorch_model\nfrom botorch.acquisition import ExpectedImprovement\nfrom botorch.exceptions import BadInitialCandidatesWarning\nfrom botorch.models.gp_regression import SingleTaskGP\nfrom gpytorch.distributions import MultivariateNormal\nfrom gpytorch.kernels import ScaleKernel\nfrom gpytorch.likelihoods import GaussianLikelihood\nfrom gpytorch.means import ConstantMean\nfrom gpytorch.mlls import ExactMarginalLogLikelihood\nfrom sklearn.model_selection import train_test_split\n\nfrom gauche.dataloader import MolPropLoader",
      "names": [
        {
          "import_components": [
            "time"
          ],
          "code_str": "time",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "time"
        },
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 7,
          "end_lineno": 7,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 7,
          "end_lineno": 7,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 23,
          "end_lineno": 23,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_optimisation_over_molecules",
        "ref_id": "Bayesian-Optimisation-Over-Molecules",
        "headings": [
          "Bayesian Optimisation Over Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel\n\n# We define our custom GP surrogate model using the Tanimoto kernel\n\nclass TanimotoGP(SingleTaskGP):\n\n    def __init__(self, train_X, train_Y):\n        super().__init__(train_X, train_Y, likelihood=GaussianLikelihood())\n        self.mean_module = ConstantMean()\n        self.covar_module = ScaleKernel(base_kernel=TanimotoKernel())\n        self.to(train_X)  # make sure we're on the right device/dtype\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return MultivariateNormal(mean_x, covar_x)",
      "names": [
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel"
          ],
          "code_str": "gauche.kernels.fingerprint_kernels.tanimoto_kernel",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_from",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_optimisation_over_molecules",
        "ref_id": "Bayesian-Optimisation-Over-Molecules",
        "headings": [
          "Bayesian Optimisation Over Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def initialize_model(train_x, train_obj, state_dict=None):\n    \"\"\"\n    Initialise model and loss function.\n\n    Args:\n        train_x: tensor of inputs\n        train_obj: tensor of outputs\n        state_dict: current state dict used to speed up fitting\n\n    Returns: mll object, model object\n    \"\"\"\n\n    # define model for objective\n    model = TanimotoGP(train_x, train_obj).to(train_x)\n    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n    # load state dict if it is passed\n    if state_dict is not None:\n        model.load_state_dict(state_dict)\n\n    return mll, model\n\n\ndef optimize_acqf_and_get_observation(acq_func, heldout_inputs, heldout_outputs):\n    \"\"\"\n    Optimizes the acquisition function, and returns a new candidate and an observation.\n\n    Args:\n        acq_func: Object representing the acquisition function\n        heldout_points: Tensor of heldout points\n\n    Returns: new_x, new_obj\n    \"\"\"\n\n    # Loop over the discrete set of points to evaluate the acquisition function at.\n    acq_vals = []\n    for i in range(len(heldout_outputs)):\n        acq_vals.append(acq_func(heldout_inputs[i].unsqueeze(-2)))  # use unsqueeze to append batch dimension\n\n    # observe new values\n    acq_vals = torch.tensor(acq_vals)\n    best_idx = torch.argmax(acq_vals)\n    new_x = heldout_inputs[best_idx].unsqueeze(-2)  # add batch dimension\n    new_obj = heldout_outputs[best_idx].unsqueeze(-1)  # add output dimension\n\n    # Delete the selected input and value from the heldout set.\n    heldout_inputs = torch.cat((heldout_inputs[:best_idx], heldout_inputs[best_idx+1:]), axis=0)\n    heldout_outputs = torch.cat((heldout_outputs[:best_idx], heldout_outputs[best_idx+1:]), axis=0)\n\n    return new_x, new_obj, heldout_inputs, heldout_outputs\n\n\ndef update_random_observations(best_random, heldout_inputs, heldout_outputs):\n    \"\"\"\n    Simulates a random policy by taking a the current list of best values observed randomly,\n    drawing a new random point from the heldout set, observing its value, and updating the list.\n\n    Args:\n        best_random: List of best random values observed so far\n        heldout_inputs: Tensor of inputs\n        heldout_outputs: Tensor of output values\n\n    Returns: best_random, float specifying the objective function value.\n    \"\"\"\n\n    # Take a random sample by permuting the indices and selecting the first element.\n    index = torch.randperm(len(heldout_outputs))[0]\n    next_random_best = heldout_outputs[index]\n    best_random.append(max(best_random[-1], next_random_best))\n\n    # Delete the selected input and value from the heldout set.\n    heldout_inputs = torch.cat((heldout_inputs[:index], heldout_inputs[index+1:]), axis=0)\n    heldout_outputs = torch.cat((heldout_outputs[:index], heldout_outputs[index+1:]), axis=0)\n\n    return best_random, heldout_inputs, heldout_outputs",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "argmax"
          ],
          "code_str": "torch.argmax",
          "lineno": 41,
          "end_lineno": 41,
          "context": "none",
          "resolved_location": "torch.argmax"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 46,
          "end_lineno": 46,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 47,
          "end_lineno": 47,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 66,
          "end_lineno": 66,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "torch",
            "randperm"
          ],
          "code_str": "torch.randperm",
          "lineno": 66,
          "end_lineno": 66,
          "context": "none",
          "resolved_location": "torch.randperm"
        },
        {
          "import_components": [
            "max"
          ],
          "code_str": "max",
          "lineno": 68,
          "end_lineno": 68,
          "context": "none",
          "resolved_location": "max"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 71,
          "end_lineno": 71,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 72,
          "end_lineno": 72,
          "context": "none",
          "resolved_location": "torch.cat"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_optimisation_over_molecules",
        "ref_id": "Bayesian-Optimisation-Over-Molecules",
        "headings": [
          "Bayesian Optimisation Over Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Bayesian optimisation experiment parameters, number of random trials, split size, batch size\n# and number of iterations of Bayesian optimisation.\n\nN_TRIALS = 20\nholdout_set_size = 0.95\nN_ITERS = 20\nverbose = False\n\n# Load the Photoswitch dataset\nloader = MolPropLoader()\nloader.load_benchmark(\"Photoswitch\")\n\n# We use the fragprints representations (a concatenation of Morgan fingerprints and RDKit fragment features)\nloader.featurize('ecfp_fragprints')\nX = loader.features\ny = loader.labels\n\nwarnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\nbest_observed_all_ei, best_random_all = [], []\n\n# average over multiple random trials (each trial splits the initial training set for the GP in a random manner)\nfor trial in range(1, N_TRIALS + 1):\n\n    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n    best_observed_ei, best_random = [], []\n\n    # Generate initial training data and initialize model\n    train_x_ei, heldout_x_ei, train_y_ei, heldout_y_ei = train_test_split(X, y, test_size=holdout_set_size, random_state=trial)\n    best_observed_value_ei = torch.tensor(np.max(train_y_ei))\n\n    # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n    train_x_ei = torch.tensor(train_x_ei.astype(np.float64))\n    heldout_x_ei = torch.tensor(heldout_x_ei.astype(np.float64))\n    train_y_ei = torch.tensor(train_y_ei)\n    heldout_y_ei = torch.tensor(heldout_y_ei)\n\n    # The initial heldout set is the same for random search\n    heldout_x_random = heldout_x_ei\n    heldout_y_random = heldout_y_ei\n\n    mll_ei, model_ei = initialize_model(train_x_ei, train_y_ei)\n\n    best_observed_ei.append(best_observed_value_ei)\n    best_random.append(best_observed_value_ei)\n\n    # run N_ITERS rounds of BayesOpt after the initial random batch\n    for iteration in range(1, N_ITERS + 1):\n\n        t0 = time.time()\n\n        # fit the model\n        fit_gpytorch_model(mll_ei)\n\n        # Use analytic acquisition function for batch size of 1.\n        EI = ExpectedImprovement(model=model_ei, best_f=(train_y_ei.to(train_y_ei)).max())\n\n        new_x_ei, new_obj_ei, heldout_x_ei, heldout_y_ei = optimize_acqf_and_get_observation(EI,\n                                                                                             heldout_x_ei,\n                                                                                             heldout_y_ei)\n\n        # update training points\n        train_x_ei = torch.cat([train_x_ei, new_x_ei])\n        train_y_ei = torch.cat([train_y_ei, new_obj_ei])\n\n        # update random search progress\n        best_random, heldout_x_random, heldout_y_random = update_random_observations(best_random,\n                                                                                     heldout_inputs=heldout_x_random,\n                                                                                     heldout_outputs=heldout_y_random)\n        best_value_ei = torch.max(new_obj_ei, best_observed_ei[-1])\n        best_observed_ei.append(best_value_ei.squeeze())\n\n        # reinitialise the model so it is ready for fitting on the next iteration\n        # use the current state dict to speed up fitting\n        mll_ei, model_ei = initialize_model(\n            train_x_ei,\n            train_y_ei,\n            model_ei.state_dict(),\n        )\n\n        t1 = time.time()\n\n        if verbose:\n            print(\n                f\"\\nBatch {iteration:>2}: best_value (random, qEI) = \"\n                f\"({max(best_random):>4.2f}, {best_value_ei:>4.2f}), \"\n                f\"time = {t1 - t0:>4.2f}.\", end=\"\"\n            )\n        else:\n            print(\".\", end=\"\")\n\n    best_observed_all_ei.append(torch.hstack(best_observed_ei))\n    best_random_all.append(torch.hstack(best_random))\n\n# Define a confience interval function for plotting.\ndef ci(y):\n    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n\niters = np.arange(N_ITERS + 1)\ny_ei = np.asarray(torch.stack(best_observed_all_ei))\ny_rnd = np.asarray(torch.stack(best_random_all))\n\ny_rnd_mean = y_rnd.mean(axis=0)\ny_ei_mean = y_ei.mean(axis=0)\ny_rnd_std = y_rnd.std(axis=0)\ny_ei_std = y_ei.std(axis=0)\n\nlower_rnd = y_rnd_mean - y_rnd_std\nupper_rnd = y_rnd_mean + y_rnd_std\nlower_ei = y_ei_mean - y_ei_std\nupper_ei = y_ei_mean + y_ei_std\n\nplt.plot(iters, y_rnd_mean, label='Random')\nplt.fill_between(iters, lower_rnd, upper_rnd, alpha=0.2)\nplt.plot(iters, y_ei_mean, label='EI')\nplt.fill_between(iters, lower_ei, upper_ei, alpha=0.2)\nplt.xlabel('Number of Iterations')\nplt.ylabel('Best Objective Value')\nplt.legend(loc=\"lower right\")\nplt.xticks(list(np.arange(1, 21)))\nplt.show()",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.featurize"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "RuntimeWarning"
          ],
          "code_str": "RuntimeWarning",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "RuntimeWarning"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 37,
          "end_lineno": 37,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 49,
          "end_lineno": 49,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "time",
            "time"
          ],
          "code_str": "time.time",
          "lineno": 51,
          "end_lineno": 51,
          "context": "none",
          "resolved_location": "time.time"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 64,
          "end_lineno": 64,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 65,
          "end_lineno": 65,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "max"
          ],
          "code_str": "torch.max",
          "lineno": 71,
          "end_lineno": 71,
          "context": "none",
          "resolved_location": "torch.max"
        },
        {
          "import_components": [
            "time",
            "time"
          ],
          "code_str": "time.time",
          "lineno": 82,
          "end_lineno": 82,
          "context": "none",
          "resolved_location": "time.time"
        },
        {
          "import_components": [
            "max"
          ],
          "code_str": "max",
          "lineno": 87,
          "end_lineno": 87,
          "context": "none",
          "resolved_location": "max"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 85,
          "end_lineno": 85,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 91,
          "end_lineno": 91,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "torch",
            "hstack"
          ],
          "code_str": "torch.hstack",
          "lineno": 93,
          "end_lineno": 93,
          "context": "none",
          "resolved_location": "torch.hstack"
        },
        {
          "import_components": [
            "torch",
            "hstack"
          ],
          "code_str": "torch.hstack",
          "lineno": 94,
          "end_lineno": 94,
          "context": "none",
          "resolved_location": "torch.hstack"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 98,
          "end_lineno": 98,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 100,
          "end_lineno": 100,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "torch",
            "stack"
          ],
          "code_str": "torch.stack",
          "lineno": 101,
          "end_lineno": 101,
          "context": "none",
          "resolved_location": "torch.stack"
        },
        {
          "import_components": [
            "numpy",
            "asarray"
          ],
          "code_str": "np.asarray",
          "lineno": 101,
          "end_lineno": 101,
          "context": "none",
          "resolved_location": "numpy.asarray"
        },
        {
          "import_components": [
            "torch",
            "stack"
          ],
          "code_str": "torch.stack",
          "lineno": 102,
          "end_lineno": 102,
          "context": "none",
          "resolved_location": "torch.stack"
        },
        {
          "import_components": [
            "numpy",
            "asarray"
          ],
          "code_str": "np.asarray",
          "lineno": 102,
          "end_lineno": 102,
          "context": "none",
          "resolved_location": "numpy.asarray"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 114,
          "end_lineno": 114,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "fill_between"
          ],
          "code_str": "plt.fill_between",
          "lineno": 115,
          "end_lineno": 115,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.fill_between"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 116,
          "end_lineno": 116,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "fill_between"
          ],
          "code_str": "plt.fill_between",
          "lineno": 117,
          "end_lineno": 117,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.fill_between"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 118,
          "end_lineno": 118,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 120,
          "end_lineno": 120,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 121,
          "end_lineno": 121,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 121,
          "end_lineno": 121,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 121,
          "end_lineno": 121,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 122,
          "end_lineno": 122,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "notebooks/bayesian_optimisation_over_molecules",
        "ref_id": "Bayesian-Optimisation-Over-Molecules",
        "headings": [
          "Bayesian Optimisation Over Molecules"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/external_graph_kernels": [
    {
      "source": "%%capture\n# Imports\n\n# To import from the gauche package\nimport sys\nsys.path.append('..')\nsys.path.append('../benchmarks/')\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nimport torch\n\nfrom gauche.dataloader import DataLoaderMP\nfrom gauche.dataloader.data_utils import transform_data\nfrom gpytorch_metrics import negative_log_predictive_density, mean_standardized_log_loss, quantile_coverage_error\n\nimport gpytorch\n\nif gpytorch.__version__ != '1.7.0':\n    raise RuntimeError('Please install gpytorch==1.7.0 to run use the current SIGP implementation.')\n\nfrom botorch import fit_gpytorch_model\nfrom rdkit.Chem import MolFromSmiles\nfrom grakel import Graph\nfrom grakel.kernels import NeighborhoodSubgraphPairwiseDistance, \\\n    ShortestPath, RandomWalk, WeisfeilerLehman, GraphletSampling, PyramidMatch, \\\n    NeighborhoodHash, VertexHistogram, EdgeHistogram, WeisfeilerLehmanOptimalAssignment\n\nimport scipy.sparse as sp\nimport warnings\n\nwarnings.filterwarnings(action='ignore', category=UserWarning, module=r'gpytorch')\nwarnings.filterwarnings(action='ignore', category=gpytorch.utils.warnings.NumericalWarning, module=r'gpytorch')",
      "names": [],
      "example": {
        "document": "notebooks/external_graph_kernels",
        "ref_id": "GP-Regression-on-Molecules",
        "headings": [
          "GP Regression on Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# We define our GP model using the Tanimoto kernel\n\nfrom gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel\nfrom gauche.gp import SIGP, Inputs, GraphKernel\n\nclass GraphGP(SIGP):\n    def __init__(self, train_x, train_y, likelihood, kernel):\n        super().__init__(train_x, train_y, likelihood)\n        self.mean = gpytorch.means.ConstantMean()\n        self.covariance = GraphKernel(kernel)\n\n    def forward(self, x):\n        mean = self.mean(torch.zeros(len(x.data), 1)).float()\n        covariance = self.covariance(x)\n\n        # for numerical stability\n        jitter = max(covariance.diag().mean().detach().item()*1e-4, 1e-4)\n        covariance += torch.eye(len(x.data))*jitter\n        return gpytorch.distributions.MultivariateNormal(mean, covariance)",
      "names": [
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel"
          ],
          "code_str": "gauche.kernels.fingerprint_kernels.tanimoto_kernel",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_from",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "max"
          ],
          "code_str": "max",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "max"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "notebooks/external_graph_kernels",
        "ref_id": "GP-Regression-on-Molecules",
        "headings": [
          "GP Regression on Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Regression experiments parameters, number of random splits and split size\n\nn_trials = 3\ntest_set_size = 0.2",
      "names": [],
      "example": {
        "document": "notebooks/external_graph_kernels",
        "ref_id": "GP-Regression-on-Molecules",
        "headings": [
          "GP Regression on Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "bond_types = {1.0: 'S', 1.5: 'A', 2.0: 'D', 3.0: 'O'}\n\ndef to_graph(mol):\n    node_labels = {i: mol.GetAtomWithIdx(i).GetSymbol() for i in range(mol.GetNumAtoms())}\n    edges = {}\n    for bond in mol.GetBonds():\n        start_idx = bond.GetBeginAtomIdx()\n        end_idx = bond.GetEndAtomIdx()\n        bond_type = bond.GetBondTypeAsDouble()\n\n        edges[(start_idx, end_idx)] = bond_types[bond_type]\n        edges[(end_idx, start_idx)] = bond_types[bond_type]\n    edge_list = list(edges.keys())\n    assert len(edge_list) == len(set(edge_list))\n\n    if len(edge_list) == 0:\n        edge_list = [(0, 0)]\n    graph = Graph(edge_list,\n        node_labels=node_labels,\n        edge_labels=edges)\n    return graph",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "set"
          ],
          "code_str": "set",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "set"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "notebooks/external_graph_kernels",
        "ref_id": "GP-Regression-on-Molecules",
        "headings": [
          "GP Regression on Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "datasets = {'Photoswitch': '../data/property_prediction/photoswitches.csv',\n            'ESOL': '../data/property_prediction/ESOL.csv',\n            'FreeSolv': '../data/property_prediction/FreeSolv.csv',\n            # 'Lipophilicity': '../data/property_prediction/Lipophilicity.csv'\n}\n\nkwargs = dict(normalize=True)\nkernels = [\n    WeisfeilerLehman(**kwargs),\n    # GraphletSampling(**kwargs),\n    # NeighborhoodSubgraphPairwiseDistance(r=1, **kwargs),\n    # ShortestPath(**kwargs),\n    # PyramidMatch(**kwargs),\n    # NeighborhoodHash(**kwargs),\n    # VertexHistogram(**kwargs),\n    # EdgeHistogram(**kwargs),\n    # WeisfeilerLehmanOptimalAssignment(**kwargs),\n    # RandomWalk(**kwargs)\n]\n\nfor dataset_name, data_loc in datasets.items():\n    loader = DataLoaderMP()\n    loader.load_benchmark(dataset_name, data_loc)\n\n    X = [to_graph(MolFromSmiles(mol)) for mol in loader.features]\n    y = loader.labels\n    print(dataset_name); print('\\n' + '-'*50)\n    for kernel in kernels:\n        print(kernel)\n        r2_list = []; rmse_list = []; mae_list = []; nlpd_list = []; msll_list = []; qce_list = []\n        for i in range(0, n_trials):\n            np.random.seed(i); torch.manual_seed(i)\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n\n            #  We standardise the outputs but leave the inputs unchanged\n            # this seems to introduce numerical instabilities\n            _, y_train, _, y_test, y_scaler = transform_data(\n                np.zeros_like(y_train), y_train, np.zeros_like(y_test), y_test)\n\n            # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n            y_train = torch.tensor(y_train).flatten().float()\n            y_test = torch.tensor(y_test).flatten().float()\n\n            X_train = Inputs(X_train)\n            X_test = Inputs(X_test)\n\n            # initialise GP likelihood and model\n            likelihood = gpytorch.likelihoods.GaussianLikelihood()\n            model = GraphGP(X_train, y_train, likelihood, kernel)\n\n            # Find optimal model hyperparameters\n            model.train()\n            likelihood.train()\n\n            # \"Loss\" for GPs - the marginal log likelihood\n            mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n\n            # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n            # fit_gpytorch_model(mll)\n\n            optimizer = torch.optim.Adam(model.parameters(), lr=0.5)  # Includes GaussianLikelihood parameters\n\n            for j in range(150):\n                optimizer.zero_grad()\n                output = model(X_train)\n                loss = -mll(output, y_train)\n                loss.backward()\n                # print(loss.item())\n                optimizer.step()\n            # print('Training successful')\n\n            # Get into evaluation (predictive posterior) mode\n            model.eval()\n            likelihood.eval()\n\n            # full GP predictive distribution\n            trained_pred_dist = likelihood(model(X_test))\n\n            # Compute NLPD on the Test set\n            try:\n                nlpd = negative_log_predictive_density(trained_pred_dist, y_test)\n            except:\n                with gpytorch.settings.cholesky_jitter(1e-1):\n                    nlpd = negative_log_predictive_density(trained_pred_dist, y_test)\n\n            # Compute MSLL on Test set\n            msll = mean_standardized_log_loss(trained_pred_dist, y_test)\n\n            # Compute quantile coverage error on test set\n            qce = quantile_coverage_error(trained_pred_dist, y_test, quantile=95)\n\n            # print(f'NLPD: {nlpd:.2f}')\n            # print(f'MSLL: {msll:.2f}')\n            # print(f'QCE: {qce:.2f}')\n\n            # mean and variance GP prediction\n            f_pred = model(X_test)\n\n            y_pred = f_pred.mean\n\n            # Transform back to real data space to compute metrics and detach gradients\n            y_pred = y_scaler.inverse_transform(y_pred.detach().unsqueeze(dim=1))\n            y_test = y_scaler.inverse_transform(y_test.detach().unsqueeze(dim=1))\n\n            # Output Standardised RMSE and RMSE on Train Set\n            y_train = y_train.detach()\n            y_pred_train = model(X_train).mean.detach()\n            train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n            train_rmse = np.sqrt(\n                mean_squared_error(y_scaler.inverse_transform(y_train.unsqueeze(dim=1)),\n                                   y_scaler.inverse_transform(y_pred_train.unsqueeze(dim=1))))\n            # print(\"\\nStandardised Train RMSE: {:.3f}\".format(train_rmse_stan))\n            # print(\"Train RMSE: {:.3f}\".format(train_rmse))\n\n            # Compute R^2, RMSE and MAE on Test set\n            score = r2_score(y_test, y_pred)\n            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n            mae = mean_absolute_error(y_test, y_pred)\n\n            # print(\"\\nR^2: {:.3f}\".format(score))\n            # print(\"RMSE: {:.3f}\".format(rmse))\n            # print(\"MAE: {:.3f}\".format(mae))\n\n            nlpd_list.append(nlpd)\n            msll_list.append(msll)\n            qce_list.append(qce)\n\n            r2_list.append(score)\n            rmse_list.append(rmse)\n            mae_list.append(mae)\n\n        nlpd_list = torch.tensor(nlpd_list)\n        msll_list = torch.tensor(msll_list)\n        qce_list = torch.tensor(qce_list)\n\n        r2_list = np.array(r2_list)\n        rmse_list = np.array(rmse_list)\n        mae_list = np.array(mae_list)\n\n        print(\"\\nmean NLPD: {:.4f} +- {:.4f}\".format(torch.mean(nlpd_list), torch.std(nlpd_list) / torch.sqrt(torch.tensor(n_trials))))\n        print(\"mean MSLL: {:.4f} +- {:.4f}\".format(torch.mean(msll_list), torch.std(msll_list) / np.sqrt(torch.tensor(n_trials))))\n        print(\"mean QCE: {:.4f} +- {:.4f}\".format(torch.mean(qce_list), torch.std(qce_list) / np.sqrt(torch.tensor(n_trials))))\n\n        print(\"mean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list) / np.sqrt(len(r2_list))))\n        print(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list) / np.sqrt(len(rmse_list))))\n        print(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list) / np.sqrt(len(mae_list))))",
      "names": [
        {
          "import_components": [
            "dict"
          ],
          "code_str": "dict",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "dict"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 63,
          "end_lineno": 63,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 140,
          "end_lineno": 140,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 141,
          "end_lineno": 141,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 142,
          "end_lineno": 142,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 146,
          "end_lineno": 146,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 146,
          "end_lineno": 146,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/external_graph_kernels",
        "ref_id": "GP-Regression-on-Molecules",
        "headings": [
          "GP Regression on Molecules"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/gp_regression_on_molecules": [
    {
      "source": "# Imports\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n\nimport time\n\nfrom botorch import fit_gpytorch_model\nimport gpytorch\nfrom mordred import Calculator, descriptors\nimport numpy as np\nfrom rdkit import Chem\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nimport torch\n\nfrom gauche.dataloader import MolPropLoader\nfrom gauche.dataloader.data_utils import transform_data",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "time"
          ],
          "code_str": "time",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "time"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition"
          ],
          "code_str": "sklearn.decomposition",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_from",
          "resolved_location": "sklearn.decomposition"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition",
            "PCA"
          ],
          "code_str": "PCA",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_target",
          "resolved_location": "sklearn.decomposition._pca.PCA"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "sklearn",
            "metrics"
          ],
          "code_str": "sklearn.metrics",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_from",
          "resolved_location": "sklearn.metrics"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing"
          ],
          "code_str": "sklearn.preprocessing",
          "lineno": 16,
          "end_lineno": 16,
          "context": "import_from",
          "resolved_location": "sklearn.preprocessing"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing",
            "StandardScaler"
          ],
          "code_str": "StandardScaler",
          "lineno": 16,
          "end_lineno": 16,
          "context": "import_target",
          "resolved_location": "sklearn.preprocessing._data.StandardScaler"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 17,
          "end_lineno": 17,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 19,
          "end_lineno": 19,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils"
          ],
          "code_str": "gauche.dataloader.data_utils",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_from",
          "resolved_location": "gauche.dataloader.data_utils"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        }
      ],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "GP-Regression-on-Molecules",
        "headings": [
          "GP Regression on Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# We define our GP model using the Tanimoto kernel\n\nfrom gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel\nfrom gpytorch.kernels import RQKernel\n\nclass ExactGPModel(gpytorch.models.ExactGP):\n    def __init__(self, train_x, train_y, likelihood):\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.ConstantMean()\n        # We use the Tanimoto kernel to work with molecular fingerprint representations\n        self.covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n\n# For the continuous Mordred descriptors we use a GP with rational quadratic kernel\n\nclass ExactMordredGPModel(gpytorch.models.ExactGP):\n    def __init__(self, train_x, train_y, likelihood):\n        super(ExactMordredGPModel, self).__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.ConstantMean()\n        # We use the RQ kernel to work with Mordred descriptors\n        self.covar_module = gpytorch.kernels.ScaleKernel(RQKernel())\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)",
      "names": [
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel"
          ],
          "code_str": "gauche.kernels.fingerprint_kernels.tanimoto_kernel",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_from",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "Defining-a-Molecular-Kernel",
        "headings": [
          "GP Regression on Molecules",
          "Defining a Molecular Kernel"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Regression experiments parameters, number of random splits and split size\n\nn_trials = 20\ntest_set_size = 0.2",
      "names": [],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "GP-Regression-on-the-Photoswitch-Dataset",
        "headings": [
          "GP Regression on Molecules",
          "GP Regression on the Photoswitch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Load the Photoswitch dataset\n\nloader = MolPropLoader()\nloader.load_benchmark(\"Photoswitch\")\n\n# Featurise the molecules.\n\n# We use the fragprints representations (a concatenation of Morgan fingerprints and RDKit fragment features)\n\nloader.featurize('ecfp_fragprints')\nX_fragprints = loader.features\ny = loader.labels\n\n# we can also consider a bag of characters summary of the molecule's SMILES string representations\nloader.load_benchmark(\"Photoswitch\")\nloader.featurize('bag_of_smiles', max_ngram=5)\nX_boc = loader.features",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.featurize"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.featurize"
        }
      ],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "GP-Regression-on-the-Photoswitch-Dataset",
        "headings": [
          "GP Regression on Molecules",
          "GP Regression on the Photoswitch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Compute Mordred descriptors.\"\"\"\n\nloader = MolPropLoader()\nloader.load_benchmark(\"Photoswitch\")\n\n# Mordred descriptor computation is expensive\ncalc = Calculator(descriptors, ignore_3D=False)\nmols = [Chem.MolFromSmiles(smi) for smi in loader.features]\nt0 = time.time()\nX_mordred = [calc(mol) for mol in mols]\nt1 = time.time()\nprint(f'Mordred descriptor computation takes {t1 - t0} seconds')\nX_mordred = np.array(X_mordred).astype(np.float64)\n\n\"\"\"Collect nan indices\"\"\"\n\nnan_dims = []\n\nfor i in range(len(X_mordred)):\n    nan_indices = list(np.where(np.isnan(X_mordred[i, :]))[0])\n    for dim in nan_indices:\n        if dim not in nan_dims:\n            nan_dims.append(dim)\n\nX_mordred = np.delete(X_mordred, nan_dims, axis=1)",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "time",
            "time"
          ],
          "code_str": "time.time",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "time.time"
        },
        {
          "import_components": [
            "time",
            "time"
          ],
          "code_str": "time.time",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "time.time"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "isnan"
          ],
          "code_str": "np.isnan",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.isnan"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "numpy",
            "delete"
          ],
          "code_str": "np.delete",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.delete"
        }
      ],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "GP-Regression-on-the-Photoswitch-Dataset",
        "headings": [
          "GP Regression on Molecules",
          "GP Regression on the Photoswitch Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\") # Turn off GPyTorch warnings\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n\ndef evaluate_model(X, y, use_mordred=False):\n    \"\"\"Helper function for model evaluation.\n\n    Args:\n        X: n x d NumPy array of inputs representing molecules\n        y: n x 1 NumPy array of output labels\n        use_mordred: Bool specifying whether the X features are mordred descriptors. If yes, then apply PCA.\n    Returns:\n        regression metrics and confidence-error curve plot.\n    \"\"\"\n\n    # initialise performance metric lists\n    r2_list = []\n    rmse_list = []\n    mae_list = []\n\n    # We pre-allocate array for plotting confidence-error curves\n\n    _, _, _, y_test = train_test_split(X, y, test_size=test_set_size)  # To get test set size\n    n_test = len(y_test)\n\n    mae_confidence_list = np.zeros((n_trials, n_test))\n\n    print('\\nBeginning training loop...')\n\n    for i in range(0, n_trials):\n\n        print(f'Starting trial {i}')\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n\n        if use_mordred:\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n            pca_mordred = PCA(n_components=51)\n            X_train = pca_mordred.fit_transform(X_train)\n            X_test = pca_mordred.transform(X_test)\n\n        #  We standardise the outputs\n        _, y_train, _, y_test, y_scaler = transform_data(X_train, y_train, X_test, y_test)\n\n        # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n        X_train = torch.tensor(X_train.astype(np.float64))\n        X_test = torch.tensor(X_test.astype(np.float64))\n        y_train = torch.tensor(y_train).flatten()\n        y_test = torch.tensor(y_test).flatten()\n\n        # initialise GP likelihood and model\n        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n        if use_mordred:\n            model = ExactMordredGPModel(X_train, y_train, likelihood)\n        else:\n            model = ExactGPModel(X_train, y_train, likelihood)\n\n        # Find optimal model hyperparameters\n        # \"Loss\" for GPs - the marginal log likelihood\n        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n\n        # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n        fit_gpytorch_model(mll)\n\n        # Get into evaluation (predictive posterior) mode\n        model.eval()\n        likelihood.eval()\n\n        # mean and variance GP prediction\n        f_pred = model(X_test)\n\n        y_pred = f_pred.mean\n        y_var = f_pred.variance\n\n        # Transform back to real data space to compute metrics and detach gradients. Must unsqueeze dimension\n        # to make compatible with inverse_transform in scikit-learn version > 1\n        y_pred = y_scaler.inverse_transform(y_pred.detach().unsqueeze(dim=1))\n        y_test = y_scaler.inverse_transform(y_test.detach().unsqueeze(dim=1))\n\n        # Compute scores for confidence curve plotting.\n\n        ranked_confidence_list = np.argsort(y_var.detach(), axis=0).flatten()\n\n        for k in range(len(y_test)):\n\n            # Construct the MAE error for each level of confidence\n\n            conf = ranked_confidence_list[0:k+1]\n            mae = mean_absolute_error(y_test[conf], y_pred[conf])\n            mae_confidence_list[i, k] = mae\n\n        # Output Standardised RMSE and RMSE on Train Set\n        y_train = y_train.detach()\n        y_pred_train = model(X_train).mean.detach()\n        train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n        train_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(y_train.unsqueeze(dim=1)),\n                                                y_scaler.inverse_transform(y_pred_train.unsqueeze(dim=1))))\n\n        # Compute R^2, RMSE and MAE on Test set\n        score = r2_score(y_test, y_pred)\n        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n        mae = mean_absolute_error(y_test, y_pred)\n\n        r2_list.append(score)\n        rmse_list.append(rmse)\n        mae_list.append(mae)\n\n    r2_list = np.array(r2_list)\n    rmse_list = np.array(rmse_list)\n    mae_list = np.array(mae_list)\n\n    print(\"\\nmean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list)/np.sqrt(len(r2_list))))\n    print(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list)/np.sqrt(len(rmse_list))))\n    print(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list)/np.sqrt(len(mae_list))))\n\n    # Plot confidence-error curves\n\n    # 1e-14 instead of 0 to for numerical reasons!\n    confidence_percentiles = np.arange(1e-14, 100, 100/len(y_test))\n\n    # We plot the Mean-absolute error confidence-error curves\n\n    mae_mean = np.mean(mae_confidence_list, axis=0)\n    mae_std = np.std(mae_confidence_list, axis=0)\n\n    mae_mean = np.flip(mae_mean)\n    mae_std = np.flip(mae_std)\n\n    # 1 sigma errorbars\n\n    lower = mae_mean - mae_std\n    upper = mae_mean + mae_std\n\n    plt.plot(confidence_percentiles, mae_mean, label='mean')\n    plt.fill_between(confidence_percentiles, lower, upper, alpha=0.2)\n    plt.xlabel('Confidence Percentile')\n    plt.ylabel('MAE (nm)')\n    plt.ylim([0, np.max(upper) + 1])\n    plt.xlim([0, 100 * ((len(y_test) - 1) / len(y_test))])\n    plt.yticks(np.arange(0, np.max(upper) + 1, 5.0))\n    plt.show()\n\n    return rmse_list, mae_list",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 37,
          "end_lineno": 37,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing",
            "StandardScaler"
          ],
          "code_str": "StandardScaler",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "sklearn.preprocessing._data.StandardScaler"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing",
            "StandardScaler",
            "()"
          ],
          "code_str": "scaler",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "sklearn.preprocessing._data.StandardScaler"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing",
            "StandardScaler",
            "()",
            "fit_transform"
          ],
          "code_str": "scaler.fit_transform",
          "lineno": 41,
          "end_lineno": 41,
          "context": "none",
          "resolved_location": "sklearn.base.TransformerMixin.fit_transform"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition",
            "PCA"
          ],
          "code_str": "PCA",
          "lineno": 43,
          "end_lineno": 43,
          "context": "none",
          "resolved_location": "sklearn.decomposition._pca.PCA"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition",
            "PCA",
            "()"
          ],
          "code_str": "pca_mordred",
          "lineno": 43,
          "end_lineno": 43,
          "context": "none",
          "resolved_location": "sklearn.decomposition._pca.PCA"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition",
            "PCA",
            "()",
            "fit_transform"
          ],
          "code_str": "pca_mordred.fit_transform",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "sklearn.base.TransformerMixin.fit_transform"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 48,
          "end_lineno": 48,
          "context": "none",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 51,
          "end_lineno": 51,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 51,
          "end_lineno": 51,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 52,
          "end_lineno": 52,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 52,
          "end_lineno": 52,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 53,
          "end_lineno": 53,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 54,
          "end_lineno": 54,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "argsort"
          ],
          "code_str": "np.argsort",
          "lineno": 87,
          "end_lineno": 87,
          "context": "none",
          "resolved_location": "numpy.argsort"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 89,
          "end_lineno": 89,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 89,
          "end_lineno": 89,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 94,
          "end_lineno": 94,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 100,
          "end_lineno": 100,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 100,
          "end_lineno": 100,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 101,
          "end_lineno": 101,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 101,
          "end_lineno": 101,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 105,
          "end_lineno": 105,
          "context": "none",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 106,
          "end_lineno": 106,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 106,
          "end_lineno": 106,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 107,
          "end_lineno": 107,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 113,
          "end_lineno": 113,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 114,
          "end_lineno": 114,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 115,
          "end_lineno": 115,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 117,
          "end_lineno": 117,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 117,
          "end_lineno": 117,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 117,
          "end_lineno": 117,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 117,
          "end_lineno": 117,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 117,
          "end_lineno": 117,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 118,
          "end_lineno": 118,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 118,
          "end_lineno": 118,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 118,
          "end_lineno": 118,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 118,
          "end_lineno": 118,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 118,
          "end_lineno": 118,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 124,
          "end_lineno": 124,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 124,
          "end_lineno": 124,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 128,
          "end_lineno": 128,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 129,
          "end_lineno": 129,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 131,
          "end_lineno": 131,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 132,
          "end_lineno": 132,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 139,
          "end_lineno": 139,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "fill_between"
          ],
          "code_str": "plt.fill_between",
          "lineno": 140,
          "end_lineno": 140,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.fill_between"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 141,
          "end_lineno": 141,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 142,
          "end_lineno": 142,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 143,
          "end_lineno": 143,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 143,
          "end_lineno": 143,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 144,
          "end_lineno": 144,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "yticks"
          ],
          "code_str": "plt.yticks",
          "lineno": 145,
          "end_lineno": 145,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.yticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 146,
          "end_lineno": 146,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "Model-Evaluation",
        "headings": [
          "GP Regression on Molecules",
          "Model Evaluation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "rmse_fragprints, mae_fragprints = evaluate_model(X_fragprints, y)",
      "names": [],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "Model-Evaluation",
        "headings": [
          "GP Regression on Molecules",
          "Model Evaluation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "rmse_boc, mae_boc = evaluate_model(X_boc, y)",
      "names": [],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "Model-Evaluation",
        "headings": [
          "GP Regression on Molecules",
          "Model Evaluation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "rmse_mordred, mae_mordred = evaluate_model(X_mordred, y, use_mordred=True)",
      "names": [],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "Model-Evaluation",
        "headings": [
          "GP Regression on Molecules",
          "Model Evaluation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Wilcoxon signed rank test\"\"\"\n\nfrom scipy.stats import wilcoxon\n\n# RMSE\nprint(f'Wilcoxon Signed Rank Test on the RMSE metric is:\\n {wilcoxon(rmse_fragprints, rmse_mordred)}\\n')\n\n# MAE\nprint(f'Wilcoxon Signed Rank Test on the MAE metric is:\\n {wilcoxon(mae_fragprints, mae_mordred)}\\n')",
      "names": [
        {
          "import_components": [
            "scipy",
            "stats"
          ],
          "code_str": "scipy.stats",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_from",
          "resolved_location": "scipy.stats"
        },
        {
          "import_components": [
            "scipy",
            "stats",
            "wilcoxon"
          ],
          "code_str": "wilcoxon",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "scipy.stats.wilcoxon"
        },
        {
          "import_components": [
            "scipy",
            "stats",
            "wilcoxon"
          ],
          "code_str": "wilcoxon",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "scipy.stats.wilcoxon"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "scipy",
            "stats",
            "wilcoxon"
          ],
          "code_str": "wilcoxon",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "scipy.stats.wilcoxon"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/gp_regression_on_molecules",
        "ref_id": "Model-Evaluation",
        "headings": [
          "GP Regression on Molecules",
          "Model Evaluation"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/loading_and_featurising_molecules": [
    {
      "source": "from gauche.dataloader import MolPropLoader\n\n# load a benchmark dataset\nloader = MolPropLoader()\nloader.load_benchmark(\"Photoswitch\")",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        }
      ],
      "example": {
        "document": "notebooks/loading_and_featurising_molecules",
        "ref_id": "Molecular-Property-Prediction",
        "headings": [
          "Loading and Featurising Molecular Data",
          "Molecular Property Prediction"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "display(loader.features[:5])\ndisplay(loader.labels[:5])",
      "names": [],
      "example": {
        "document": "notebooks/loading_and_featurising_molecules",
        "ref_id": "Molecular-Property-Prediction",
        "headings": [
          "Loading and Featurising Molecular Data",
          "Molecular Property Prediction"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "loader.featurize(\"ecfp_fingerprints\")\nloader.features[:5]",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.featurize"
        }
      ],
      "example": {
        "document": "notebooks/loading_and_featurising_molecules",
        "ref_id": "Molecular-Property-Prediction",
        "headings": [
          "Loading and Featurising Molecular Data",
          "Molecular Property Prediction"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# load dataset again to undo featurisation\nloader = MolPropLoader()\nloader.load_benchmark(\"Photoswitch\")\n\n# define custom featurisation function\ndef smiles_length(smiles):\n    return [len(s) for s in smiles]\n\nloader.featurize(smiles_length)\nloader.features[:5]",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.featurize"
        }
      ],
      "example": {
        "document": "notebooks/loading_and_featurising_molecules",
        "ref_id": "Molecular-Property-Prediction",
        "headings": [
          "Loading and Featurising Molecular Data",
          "Molecular Property Prediction"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "from gauche.dataloader import ReactionLoader\n\n# load a benchmark dataset\nloader = ReactionLoader()\nloader.load_benchmark(\"DreherDoyleRXN\")\n\ndisplay(loader.features[:5])\nloader.labels[:5]",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader"
          ],
          "code_str": "ReactionLoader",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader"
          ],
          "code_str": "ReactionLoader",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader.load_benchmark"
        }
      ],
      "example": {
        "document": "notebooks/loading_and_featurising_molecules",
        "ref_id": "Reaction-Yield-Prediction",
        "headings": [
          "Loading and Featurising Molecular Data",
          "Reaction Yield Prediction"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "loader.featurize(\"drfp\")\nloader.features[:5]",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader.featurize"
        }
      ],
      "example": {
        "document": "notebooks/loading_and_featurising_molecules",
        "ref_id": "Reaction-Yield-Prediction",
        "headings": [
          "Loading and Featurising Molecular Data",
          "Reaction Yield Prediction"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# load dataset again to undo featurisation\nloader = ReactionLoader()\nloader.load_benchmark(\"DreherDoyleRXN\")\n\n# define custom featurisation function\ndef smiles_length(smiles):\n    return [len(s) for s in smiles]\n\nloader.featurize(smiles_length)\nloader.features[:5]",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader"
          ],
          "code_str": "ReactionLoader",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader.load_benchmark"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "ReactionLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "gauche.dataloader.reaction_loader.ReactionLoader.featurize"
        }
      ],
      "example": {
        "document": "notebooks/loading_and_featurising_molecules",
        "ref_id": "Reaction-Yield-Prediction",
        "headings": [
          "Loading and Featurising Molecular Data",
          "Reaction Yield Prediction"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/molecular_preference_learning": [
    {
      "source": "\"\"\"Library imports\"\"\"\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n\nfrom itertools import combinations\nfrom botorch import fit_gpytorch_model\nfrom botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\nimport gpytorch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom scipy.stats import kendalltau\nfrom matplotlib import pyplot as plt\nfrom gauche.dataloader import MolPropLoader\nfrom gauche.dataloader.data_utils import transform_data\nfrom gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel\n\n%matplotlib inline",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "itertools"
          ],
          "code_str": "itertools",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_from",
          "resolved_location": "itertools"
        },
        {
          "import_components": [
            "itertools",
            "combinations"
          ],
          "code_str": "combinations",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "itertools.combinations"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 12,
          "end_lineno": 12,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "scipy",
            "stats"
          ],
          "code_str": "scipy.stats",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_from",
          "resolved_location": "scipy.stats"
        },
        {
          "import_components": [
            "scipy",
            "stats",
            "kendalltau"
          ],
          "code_str": "kendalltau",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_target",
          "resolved_location": "scipy.stats.kendalltau"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils"
          ],
          "code_str": "gauche.dataloader.data_utils",
          "lineno": 16,
          "end_lineno": 16,
          "context": "import_from",
          "resolved_location": "gauche.dataloader.data_utils"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 16,
          "end_lineno": 16,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel"
          ],
          "code_str": "gauche.kernels.fingerprint_kernels.tanimoto_kernel",
          "lineno": 17,
          "end_lineno": 17,
          "context": "import_from",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 17,
          "end_lineno": 17,
          "context": "import_target",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        }
      ],
      "example": {
        "document": "notebooks/molecular_preference_learning",
        "ref_id": "Learning-an-Objective-Function-through-Interaction-with-a-Human-Chemist",
        "headings": [
          "Learning an Objective Function through Interaction with a Human Chemist"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Load the Photoswitch dataset\"\"\"\n\nloader = MolPropLoader()\nloader.load_benchmark(\"Photoswitch\")\n\n# Featurise the molecules.\n\n# We use the fragprints representations (a concatenation of Morgan fingerprints and RDKit fragment features)\n\nloader.featurize('ecfp_fragprints')\nX_fragprints = loader.features\ny = loader.labels",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.featurize"
        }
      ],
      "example": {
        "document": "notebooks/molecular_preference_learning",
        "ref_id": "Learning-an-Objective-Function-through-Interaction-with-a-Human-Chemist",
        "headings": [
          "Learning an Objective Function through Interaction with a Human Chemist"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def generate_comparisons(y, n_comp, noise=0.0, replace=False):\n    \"\"\"Function simulating the preferences of a human chemist.\n\n    Args:\n        y: 1D NumPy array of training data labels\n        n_comp: Int indicating the number of pairwise comparisons to generate\n        noise: Float indicating the level of noise in the chemist's decisions\n        replace: Bool indicating whether to generate comparisons with replacement\n\n    Returns:\n        comp_pairs: A NumPy array of comparison pairs of the form (m1, m2)\n\n    \"\"\"\n    # generate all possible pairs of elements in y\n    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n    # randomly select n_comp pairs from all_pairs\n    comp_pairs = all_pairs[\n        np.random.choice(range(len(all_pairs)), n_comp, replace=replace)\n    ]\n    # add gaussian noise to the latent y values\n    c0 = y[comp_pairs[:, 0]] + np.random.standard_normal(len(comp_pairs)) * noise\n    c1 = y[comp_pairs[:, 1]] + np.random.standard_normal(len(comp_pairs)) * noise\n    reverse_comp = (c0 < c1)\n    comp_pairs[reverse_comp, :] = np.flip(comp_pairs[reverse_comp, :], 1)\n    comp_pairs = torch.tensor(comp_pairs).long()\n\n    return comp_pairs",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "itertools",
            "combinations"
          ],
          "code_str": "combinations",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "itertools.combinations"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "choice"
          ],
          "code_str": "np.random.choice",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.random.choice"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "standard_normal"
          ],
          "code_str": "np.random.standard_normal",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "numpy.random.standard_normal"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "standard_normal"
          ],
          "code_str": "np.random.standard_normal",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "numpy.random.standard_normal"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "torch.tensor"
        }
      ],
      "example": {
        "document": "notebooks/molecular_preference_learning",
        "ref_id": "Learning-an-Objective-Function-through-Interaction-with-a-Human-Chemist",
        "headings": [
          "Learning an Objective Function through Interaction with a Human Chemist"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Utility function for computing the Kendall-Tau rank correlation between the predictions and the ground truth.\"\"\"\n\ndef eval_kt_cor(model, test_X, test_y):\n    \"\"\"Kendall-Tau rank correlation\n    Args:\n        model: Instance of pairwise GP\n        test_X: n x d Tensor of test input locations\n        test_y: n x 1 Tensor of test labels\n\n    Returns:\n        The Kendall-Tau rank correlation, a number between 0 and 1.\n    \"\"\"\n    pred_y = model.posterior(test_X).mean.squeeze().detach().numpy()\n    return kendalltau(pred_y, test_y).correlation",
      "names": [
        {
          "import_components": [
            "scipy",
            "stats",
            "kendalltau"
          ],
          "code_str": "kendalltau",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "scipy.stats.kendalltau"
        }
      ],
      "example": {
        "document": "notebooks/molecular_preference_learning",
        "ref_id": "Learning-an-Objective-Function-through-Interaction-with-a-Human-Chemist",
        "headings": [
          "Learning an Objective Function through Interaction with a Human Chemist"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Utility function for model evaluation\"\"\"\n\n# Experiment parameters\nn_trials = 20\ntest_set_size = 0.2 # train/test split\nm = 500\nnoise = 0 # simulate a noiseless oracle\n\ndef evaluate_model(X, y):\n    \"\"\"Helper function for model evaluation\n    Args:\n        X: n x d NumPy array of the full set of inputs. Typically some molecular representation such as fragprints, framgents or fingerprints\n        y: n x d NumPy array of the full set of output labels\n    Returns:\n        Mean KT correlation on the train set, mean KT correlation on the test set.\n    \"\"\"\n\n    # initialise performance metric lists\n    kt_list_train = []\n    kt_list_test = []\n\n    print('\\nBeginning training loop...')\n\n    for i in range(0, n_trials):\n\n        print(f'Starting trial {i}')\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n\n        train_comp = torch.tensor(generate_comparisons(y_train.squeeze(-1), m, noise=noise))\n\n        # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n        X_train = torch.tensor(X_train.astype(np.float64))\n        X_test = torch.tensor(X_test.astype(np.float64))\n        y_train = torch.tensor(y_train).flatten()\n        y_test = torch.tensor(y_test).flatten()\n\n        # initialise pairwise GP model\n        model = PairwiseGP(X_train, train_comp, covar_module=gpytorch.kernels.ScaleKernel(TanimotoKernel()))\n        # Find optimal model hyperparameters\n        mll = PairwiseLaplaceMarginalLogLikelihood(model.likelihood, model)\n\n        # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n        fit_gpytorch_model(mll)\n\n        # Get into evaluation (predictive posterior) mode\n        model.eval()\n\n        # To compute metrics and detach gradients. Must unsqueeze dimension\n        y_test = y_test.detach().unsqueeze(dim=1)\n\n        # Compute Kendall-Tau rank correlation\n        train_score = eval_kt_cor(model, X_train, y_train)\n        test_score = eval_kt_cor(model, X_test, y_test)\n\n        kt_list_train.append(train_score)\n        kt_list_test.append(test_score)\n\n\n    kt_list_train = np.array(kt_list_train)\n    kt_list_test = np.array(kt_list_test)\n\n    print(\"\\nmean train KT: {:.4f} +- {:.4f}\".format(np.mean(kt_list_train), np.std(kt_list_train)/np.sqrt(len(kt_list_train))))\n    print(\"\\nmean test KT: {:.4f} +- {:.4f}\".format(np.mean(kt_list_test), np.std(kt_list_test)/np.sqrt(len(kt_list_test))))",
      "names": [
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 60,
          "end_lineno": 60,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 61,
          "end_lineno": 61,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 63,
          "end_lineno": 63,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 63,
          "end_lineno": 63,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 63,
          "end_lineno": 63,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 63,
          "end_lineno": 63,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 63,
          "end_lineno": 63,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 64,
          "end_lineno": 64,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 64,
          "end_lineno": 64,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 64,
          "end_lineno": 64,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 64,
          "end_lineno": 64,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 64,
          "end_lineno": 64,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/molecular_preference_learning",
        "ref_id": "Learning-an-Objective-Function-through-Interaction-with-a-Human-Chemist",
        "headings": [
          "Learning an Objective Function through Interaction with a Human Chemist"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "evaluate_model(X_fragprints, y)",
      "names": [],
      "example": {
        "document": "notebooks/molecular_preference_learning",
        "ref_id": "Learning-an-Objective-Function-through-Interaction-with-a-Human-Chemist",
        "headings": [
          "Learning an Objective Function through Interaction with a Human Chemist"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/multitask_gp_regression_on_molecules": [
    {
      "source": "# Imports\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n\nfrom botorch import fit_gpytorch_model\nimport gpytorch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nimport torch\n\nfrom gauche.dataloader import MolPropLoader\nfrom gauche.dataloader.data_utils import transform_data",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 8,
          "end_lineno": 8,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "sklearn",
            "metrics"
          ],
          "code_str": "sklearn.metrics",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_from",
          "resolved_location": "sklearn.metrics"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils"
          ],
          "code_str": "gauche.dataloader.data_utils",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_from",
          "resolved_location": "gauche.dataloader.data_utils"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        }
      ],
      "example": {
        "document": "notebooks/multitask_gp_regression_on_molecules",
        "ref_id": "Multitask-Learning-with-Gaussian-Processes",
        "headings": [
          "Multitask GP Regression on Molecules",
          "Multitask Learning with Gaussian Processes"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# We define our MOGP model using the Tanimoto kernel\n\nfrom gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel\n\nnum_tasks = 4 # number of tasks i.e. labels\nrank = 1 # increasing the rank hyperparameter allows the model to learn more expressive\n         # correlations between objectives at the expense of increasing the number of\n         # model hyperparameters and potentially overfitting.\n\nclass MultitaskGPModel(gpytorch.models.ExactGP):\n    def __init__(self, train_x, train_y, likelihood):\n        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.ConstantMean()\n        self.covar_module = TanimotoKernel()\n\n        # We learn an IndexKernel for 4 tasks\n        # (so we'll actually learn 4x4=16 tasks with correlations)\n        self.task_covar_module = gpytorch.kernels.IndexKernel(num_tasks=4, rank=1)\n\n    def forward(self, x, i):\n        mean_x = self.mean_module(x)\n\n        # Get input-input covariance\n        covar_x = self.covar_module(x)\n        # Get task-task covariance\n        covar_i = self.task_covar_module(i)\n        # Multiply the two together to get the covariance we want\n        covar = covar_x.mul(covar_i)\n\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar)",
      "names": [
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel"
          ],
          "code_str": "gauche.kernels.fingerprint_kernels.tanimoto_kernel",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_from",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        }
      ],
      "example": {
        "document": "notebooks/multitask_gp_regression_on_molecules",
        "ref_id": "Multitask-Learning-with-Gaussian-Processes",
        "headings": [
          "Multitask GP Regression on Molecules",
          "Multitask Learning with Gaussian Processes"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Regression experiment parameters, number of random splits and train/test split size\n\nn_trials = 20\ntest_set_size = 0.2",
      "names": [],
      "example": {
        "document": "notebooks/multitask_gp_regression_on_molecules",
        "ref_id": "Multitask-Learning-with-Gaussian-Processes",
        "headings": [
          "Multitask GP Regression on Molecules",
          "Multitask Learning with Gaussian Processes"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Load the Photoswitch dataset\n\nloader = MolPropLoader()\n\n# Define a utility function for dataloading\n\ndef load_task_data(task,\n                   loader=MolPropLoader(),\n                   path='Photoswitch',\n                   representation='ecfp_fragprints'):\n    \"\"\"Load data for a given task.\n\n    Args:\n        task: str specifying the task to load data for.\n        One of ['Photoswitch', 'Photoswitch_E_n_pi', 'Photoswitch_Z_pi_pi', 'Photoswitch_Z_n_pi']\n        loader: DataLoader object\n        path: str specifying dataset.\n        representation: str specifying representation. One of ['ecfp_fingerprints', 'ecfp_fragprints', 'fragments']\n\n    Returns:\n        X_task: tensor of features for task\n        y_task: tensor of labels for task\n    \"\"\"\n\n    if representation not in ['ecfp_fragprints', 'ecfp_fingerprints', 'fragments']:\n        raise ValueError('representation not valid.'\n                         'Please choose one of ecfp_fragprints, ecfp_fingerprints, fragments')\n\n    if task not in ['Photoswitch', 'Photoswitch_E_n_pi', 'Photoswitch_Z_pi_pi', 'Photoswitch_Z_n_pi']:\n        raise ValueError('task not valid. Please choose one of Photoswitch,'\n                         'Photoswitch_E_n_pi, Photoswitch_Z_pi_pi, Photoswitch_Z_n_pi')\n\n    loader.load_benchmark(path)\n\n    # Featurise the molecules.\n    # We use the fragprints representations (a concatenation of Morgan fingerprints and RDKit fragment features)\n\n    loader.featurize(representation)\n    X_task = torch.from_numpy(loader.features)\n    y_task = torch.from_numpy(loader.labels)\n\n    return X_task, y_task\n\n# Load features X1-X4 and properties (tasks) y1-y4.\n\nX1, y1 = load_task_data('Photoswitch')\nX2, y2 = load_task_data('Photoswitch_E_n_pi')\nX3, y3 = load_task_data('Photoswitch_Z_pi_pi')\nX4, y4 = load_task_data('Photoswitch_Z_n_pi')",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "ValueError"
          ],
          "code_str": "ValueError",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "ValueError"
        },
        {
          "import_components": [
            "ValueError"
          ],
          "code_str": "ValueError",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "ValueError"
        },
        {
          "import_components": [
            "torch",
            "from_numpy"
          ],
          "code_str": "torch.from_numpy",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "torch.from_numpy"
        },
        {
          "import_components": [
            "torch",
            "from_numpy"
          ],
          "code_str": "torch.from_numpy",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "torch.from_numpy"
        }
      ],
      "example": {
        "document": "notebooks/multitask_gp_regression_on_molecules",
        "ref_id": "Multitask-Learning-with-Gaussian-Processes",
        "headings": [
          "Multitask GP Regression on Molecules",
          "Multitask Learning with Gaussian Processes"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Helper function for model evaluation.\n\"\"\"\n\ndef prevent_test_leakage(x1, x2, x3, y1, y2, y3, X_test):\n    \"\"\"\n    Function to prevent test leakage in train/test splits for multitask learning, for example,\n    for test data point x_i, do not provide the model with auxiliary tasks P2-P4 when predicting P1.\n\n    param: x1, x2, x3: input molecules for other tasks\n    param: y1, y2, y3: labels for other tasks\n    param: X_test: the test molecules\n    \"\"\"\n\n    other_tasks = [x1, x2, x3]\n    other_labels = [y1, y2, y3]\n    for i in range(len(other_tasks)):\n        indices_to_delete = []\n        for j in range(len(other_tasks[i])):\n            other_mol = other_tasks[i][j]\n            if np.any([np.array_equal(other_mol, mol) for mol in X_test]) == True:\n                indices_to_delete.append(j)\n        indices_to_delete.reverse()\n        for index in indices_to_delete:\n            other_tasks[i] = np.delete(other_tasks[i], index, axis=0)\n            other_labels[i] = np.delete(other_labels[i], index, axis=0)\n\n    x1, x2, x3 = other_tasks[0], other_tasks[1], other_tasks[2]\n    y1, y2, y3 = other_labels[0], other_labels[1], other_labels[2]\n\n    return x1, x2, x3, y1, y2, y3\n\n# Experiment parameters, train/test split and task to run prediction for\ntest_set_size = 0.2\ntask = 'e_iso_pi'\n\nr2_list = []\nrmse_list = []\nmae_list = []\n\nprint('\\nBeginning training loop...')\n\nfor i in range(0, n_trials):\n\n    print(f'Starting trial {i}')\n\n    if task == 'e_iso_pi':\n        X_task = X1\n        y_task = y1\n    elif task == 'z_iso_pi':\n        X_task = X2\n        y_task = y2\n    elif task == 'e_iso_n':\n        X_task = X3\n        y_task = y3\n    else:\n        X_task = X4\n        y_task = y4\n\n    X_train, X_test, y_train, y_test = train_test_split(X_task, y_task, test_size=test_set_size, random_state=i)\n\n    # Partition the training data into tasks (most difficult part of training a multioutput GP!)\n\n    if task == 'e_iso_pi':\n\n        # Modify the x-values for the other tasks to exclude X_test\n        X2_new, X3_new, X4_new, y2_new, y3_new, y4_new = \\\n            prevent_test_leakage(X2, X3, X4, y2, y3, y4, X_test)\n\n        train_i_task1 = torch.full((X_train.shape[0], 1), dtype=torch.long, fill_value=0)\n        train_i_task2 = torch.full((X2_new.shape[0], 1), dtype=torch.long, fill_value=1)\n        train_i_task3 = torch.full((X3_new.shape[0], 1), dtype=torch.long, fill_value=2)\n        train_i_task4 = torch.full((X4_new.shape[0], 1), dtype=torch.long, fill_value=3)\n\n        full_train_x = torch.cat([X_train, X2_new, X3_new, X4_new])\n        full_train_y = torch.cat([y_train, y2_new, y3_new, y4_new]).flatten()\n\n        test_i_task = torch.full((X_test.shape[0], 1), dtype=torch.long, fill_value=0)\n\n\n    elif task == 'e_iso_n':\n        X1, X3, X4, y1, y3, y4 = \\\n            prevent_test_leakage(X1, X3, X4, y1, y3, y4, X_test)\n\n        train_i_task1 = torch.full((X1.shape[0], 1), dtype=torch.long, fill_value=0)\n        train_i_task2 = torch.full((X_train.shape[0], 1), dtype=torch.long, fill_value=1)\n        train_i_task3 = torch.full((X3.shape[0], 1), dtype=torch.long, fill_value=2)\n        train_i_task4 = torch.full((X4.shape[0], 1), dtype=torch.long, fill_value=3)\n\n        full_train_x = torch.cat([X1, X_train, X3, X4])\n        full_train_y = torch.cat([y1, y_train, y3, y4])\n\n        test_i_task = torch.full((X_test.shape[0], 1), dtype=torch.long, fill_value=1)\n\n\n    elif task == 'z_iso_pi':\n        X1, X2, X4, y1, y2, y4 = \\\n            prevent_test_leakage(X1, X2, X4, y1, y2, y4, X_test)\n\n        train_i_task1 = torch.full((X1.shape[0], 1), dtype=torch.long, fill_value=0)\n        train_i_task2 = torch.full((X2.shape[0], 1), dtype=torch.long, fill_value=1)\n        train_i_task3 = torch.full((X_train.shape[0], 1), dtype=torch.long, fill_value=2)\n        train_i_task4 = torch.full((X4.shape[0], 1), dtype=torch.long, fill_value=3)\n\n        full_train_x = torch.cat([X1, X2, X_train, X4])\n        full_train_y = torch.cat([y1, y2, y_train, y4])\n\n        test_i_task = torch.full((X_test.shape[0], 1), dtype=torch.long, fill_value=2)\n\n\n    else:\n        X1, X2, X3, y1, y2, y3 = \\\n            prevent_test_leakage(X1, X2, X3, y1, y2, y3, X_test)\n\n        train_i_task1 = torch.full((X1.shape[0], 1), dtype=torch.long, fill_value=0)\n        train_i_task2 = torch.full((X2.shape[0], 1), dtype=torch.long, fill_value=1)\n        train_i_task3 = torch.full((X3.shape[0], 1), dtype=torch.long, fill_value=2)\n        train_i_task4 = torch.full((X_train.shape[0], 1), dtype=torch.long, fill_value=3)\n\n        full_train_x = torch.cat([X1, X2, X3, X_train])\n        full_train_y = torch.cat([y1, y2, y3, y_train])\n\n        test_i_task = torch.full((X_test.shape[0], 1), dtype=torch.long, fill_value=3)\n\n\n    full_train_i = torch.cat([train_i_task1, train_i_task2, train_i_task3, train_i_task4])\n\n    # Gaussian likelihood\n    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n\n    # Here we have two items that we're passing in as train_inputs\n    model = MultitaskGPModel((full_train_x.float(), full_train_i.float()), full_train_y.float(), likelihood)\n\n    # \"Loss\" for GPs - the marginal log likelihood\n    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n\n    # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n    # Set the jitter level larger than the default for the MOGP\n    with gpytorch.settings.cholesky_jitter(1e-3):\n        fit_gpytorch_model(mll)\n\n    # Get into evaluation (predictive posterior) mode\n    model.eval()\n    likelihood.eval()\n\n    # The gpytorch.settings.fast_pred_var flag activates LOVE (for fast variances)\n    # See https://arxiv.org/abs/1803.06058\n    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n        observed_pred_y = likelihood(model(X_test.float(), test_i_task.float()))\n\n    y_pred = observed_pred_y.mean\n\n    # Compute R^2, RMSE and MAE on Test set\n    score = r2_score(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    mae = mean_absolute_error(y_test, y_pred)\n\n    print(rmse)\n\n    r2_list.append(score)\n    rmse_list.append(rmse)\n    mae_list.append(mae)\n\nr2_list = np.array(r2_list)\nrmse_list = np.array(rmse_list)\nmae_list = np.array(mae_list)\n\nprint(\"\\nmean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list)/np.sqrt(len(r2_list))))\nprint(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list)/np.sqrt(len(rmse_list))))\nprint(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list)/np.sqrt(len(mae_list))))",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "array_equal"
          ],
          "code_str": "np.array_equal",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.array_equal"
        },
        {
          "import_components": [
            "numpy",
            "any"
          ],
          "code_str": "np.any",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.any"
        },
        {
          "import_components": [
            "numpy",
            "delete"
          ],
          "code_str": "np.delete",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.delete"
        },
        {
          "import_components": [
            "numpy",
            "delete"
          ],
          "code_str": "np.delete",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.delete"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 42,
          "end_lineno": 42,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 59,
          "end_lineno": 59,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 69,
          "end_lineno": 69,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 70,
          "end_lineno": 70,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 71,
          "end_lineno": 71,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 72,
          "end_lineno": 72,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 74,
          "end_lineno": 74,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 75,
          "end_lineno": 75,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 77,
          "end_lineno": 77,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 84,
          "end_lineno": 84,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 85,
          "end_lineno": 85,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 86,
          "end_lineno": 86,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 87,
          "end_lineno": 87,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 89,
          "end_lineno": 89,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 90,
          "end_lineno": 90,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 92,
          "end_lineno": 92,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 99,
          "end_lineno": 99,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 100,
          "end_lineno": 100,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 101,
          "end_lineno": 101,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 102,
          "end_lineno": 102,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 104,
          "end_lineno": 104,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 105,
          "end_lineno": 105,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 107,
          "end_lineno": 107,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 114,
          "end_lineno": 114,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 115,
          "end_lineno": 115,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 116,
          "end_lineno": 116,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 117,
          "end_lineno": 117,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 120,
          "end_lineno": 120,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "full"
          ],
          "code_str": "torch.full",
          "lineno": 122,
          "end_lineno": 122,
          "context": "none",
          "resolved_location": "torch.full"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 125,
          "end_lineno": 125,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "no_grad"
          ],
          "code_str": "torch.no_grad",
          "lineno": 147,
          "end_lineno": 147,
          "context": "none",
          "resolved_location": "torch.autograd.grad_mode.no_grad"
        },
        {
          "import_components": [
            "gpytorch",
            "likelihoods",
            "GaussianLikelihood",
            "()",
            "()"
          ],
          "code_str": "observed_pred_y",
          "lineno": 148,
          "end_lineno": 148,
          "context": "none",
          "resolved_location": "torch.distributions.distribution.Distribution"
        },
        {
          "import_components": [
            "gpytorch",
            "likelihoods",
            "GaussianLikelihood",
            "()",
            "()",
            "mean"
          ],
          "code_str": "observed_pred_y.mean",
          "lineno": 150,
          "end_lineno": 150,
          "context": "none",
          "resolved_location": "torch.distributions.distribution.Distribution.mean"
        },
        {
          "import_components": [
            "gpytorch",
            "likelihoods",
            "GaussianLikelihood",
            "()",
            "()",
            "mean"
          ],
          "code_str": "y_pred",
          "lineno": 150,
          "end_lineno": 150,
          "context": "none",
          "resolved_location": "torch.distributions.distribution.Distribution.mean"
        },
        {
          "import_components": [
            "gpytorch",
            "likelihoods",
            "GaussianLikelihood",
            "()",
            "()",
            "mean"
          ],
          "code_str": "y_pred",
          "lineno": 153,
          "end_lineno": 153,
          "context": "none",
          "resolved_location": "torch.distributions.distribution.Distribution.mean"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 153,
          "end_lineno": 153,
          "context": "none",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "gpytorch",
            "likelihoods",
            "GaussianLikelihood",
            "()",
            "()",
            "mean"
          ],
          "code_str": "y_pred",
          "lineno": 154,
          "end_lineno": 154,
          "context": "none",
          "resolved_location": "torch.distributions.distribution.Distribution.mean"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 154,
          "end_lineno": 154,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 154,
          "end_lineno": 154,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "gpytorch",
            "likelihoods",
            "GaussianLikelihood",
            "()",
            "()",
            "mean"
          ],
          "code_str": "y_pred",
          "lineno": 155,
          "end_lineno": 155,
          "context": "none",
          "resolved_location": "torch.distributions.distribution.Distribution.mean"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 155,
          "end_lineno": 155,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 157,
          "end_lineno": 157,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 163,
          "end_lineno": 163,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 164,
          "end_lineno": 164,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 165,
          "end_lineno": 165,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 167,
          "end_lineno": 167,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 167,
          "end_lineno": 167,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 167,
          "end_lineno": 167,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 167,
          "end_lineno": 167,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 167,
          "end_lineno": 167,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 168,
          "end_lineno": 168,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 168,
          "end_lineno": 168,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 168,
          "end_lineno": 168,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 168,
          "end_lineno": 168,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 168,
          "end_lineno": 168,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 169,
          "end_lineno": 169,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 169,
          "end_lineno": 169,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 169,
          "end_lineno": 169,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 169,
          "end_lineno": 169,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 169,
          "end_lineno": 169,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/multitask_gp_regression_on_molecules",
        "ref_id": "Multitask-Learning-with-Gaussian-Processes",
        "headings": [
          "Multitask GP Regression on Molecules",
          "Multitask Learning with Gaussian Processes"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/preferential_bayesian_optimisation": [
    {
      "source": "\"\"\"Imports\"\"\"\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n\nfrom botorch import fit_gpytorch_model\nfrom botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\n\nimport gpytorch\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport time\nfrom itertools import combinations\n\nfrom gauche.dataloader import MolPropLoader\nfrom gauche.dataloader.data_utils import transform_data\nfrom gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel\nfrom botorch.acquisition.preference import AnalyticExpectedUtilityOfBestOption",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 10,
          "end_lineno": 10,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 12,
          "end_lineno": 12,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 12,
          "end_lineno": 12,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "time"
          ],
          "code_str": "time",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_target",
          "resolved_location": "time"
        },
        {
          "import_components": [
            "itertools"
          ],
          "code_str": "itertools",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_from",
          "resolved_location": "itertools"
        },
        {
          "import_components": [
            "itertools",
            "combinations"
          ],
          "code_str": "combinations",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_target",
          "resolved_location": "itertools.combinations"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 17,
          "end_lineno": 17,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils"
          ],
          "code_str": "gauche.dataloader.data_utils",
          "lineno": 18,
          "end_lineno": 18,
          "context": "import_from",
          "resolved_location": "gauche.dataloader.data_utils"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 18,
          "end_lineno": 18,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel"
          ],
          "code_str": "gauche.kernels.fingerprint_kernels.tanimoto_kernel",
          "lineno": 19,
          "end_lineno": 19,
          "context": "import_from",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 19,
          "end_lineno": 19,
          "context": "import_target",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        }
      ],
      "example": {
        "document": "notebooks/preferential_bayesian_optimisation",
        "ref_id": "Preferential-Bayesian-Optimisation",
        "headings": [
          "Preferential Bayesian Optimisation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Utility function for generating ground truth preference data\"\"\"\n\ndef generate_comparisons(y, n_comp, noise=0.0, replace=False):\n    \"\"\"Function simulating the preferences of a human chemist.\n\n    Args:\n        y: 1D NumPy array of training data labels\n        n_comp: Int indicating the number of pairwise comparisons to generate\n        noise: Float indicating the level of noise in the chemist's decisions\n        replace: Bool indicating whether to generate comparisons with replacement\n\n    Returns:\n        comp_pairs: A NumPy array of comparison pairs of the form (m1, m2)\n\n    \"\"\"\n    # generate all possible pairs of elements in y\n    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n    # randomly select n_comp pairs from all_pairs\n    comp_pairs = all_pairs[\n        np.random.choice(range(len(all_pairs)), n_comp, replace=replace)\n    ]\n    # add gaussian noise to the latent y values\n    c0 = y[comp_pairs[:, 0]] + np.random.standard_normal(len(comp_pairs)) * noise\n    c1 = y[comp_pairs[:, 1]] + np.random.standard_normal(len(comp_pairs)) * noise\n    reverse_comp = (c0 < c1)\n    comp_pairs[reverse_comp, :] = np.flip(comp_pairs[reverse_comp, :], 1)\n    comp_pairs = torch.tensor(comp_pairs).long()\n\n    return comp_pairs",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "itertools",
            "combinations"
          ],
          "code_str": "combinations",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "itertools.combinations"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "choice"
          ],
          "code_str": "np.random.choice",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "numpy.random.choice"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "standard_normal"
          ],
          "code_str": "np.random.standard_normal",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "numpy.random.standard_normal"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "standard_normal"
          ],
          "code_str": "np.random.standard_normal",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "numpy.random.standard_normal"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "torch.tensor"
        }
      ],
      "example": {
        "document": "notebooks/preferential_bayesian_optimisation",
        "ref_id": "Preferential-Bayesian-Optimisation",
        "headings": [
          "Preferential Bayesian Optimisation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Utility functions for the Bayesian optimisation loop\"\"\"\n\ndef initialize_model(train_x, train_comp, state_dict=None):\n    \"\"\"Initialise model and loss function for binary Morgan fingerprints\n       using a Tanimoto kernel\n\n    Args:\n        train_x: Tensor of inputs\n        train_obj: Tensor of pairwise comparisons\n        state_dict: current_state_dict used to speed up fitting.\n\n    Returns: mll object, model object\n    \"\"\"\n\n    # Define model for objective\n    model = PairwiseGP(train_x, train_comp, covar_module=gpytorch.kernels.ScaleKernel(TanimotoKernel()))\n    mll = PairwiseLaplaceMarginalLogLikelihood(model.likelihood, model)\n    # load state_dict if it is passed\n    if state_dict is not None:\n        model.load_state_dict(state_dict)\n\n    return mll, model\n\ndef optimize_acqf_and_get_observation(acq_func, heldout_inputs, heldout_outputs):\n    \"\"\"Optimizes the acquisition function and returns a new candidate and an observation.\n\n    Args:\n        acq_func: Object representing the acquisition function.\n        heldout_inputs: Tensor of heldout inputs\n        heldout_outputs: Tensor of heldout outputs.\n    Returns:\n        new_x, new_obj\n    \"\"\"\n\n    # Loop over the discrete set of points to evaluate the acquisition function at:\n    acq_vals = []\n    for i in range(len(heldout_outputs)):\n        acq_vals.append(acq_func(heldout_inputs[i].unsqueeze(-2))) # use unsqueeze to append batch dimension\n\n    # Observe new values\n    acq_vals = torch.tensor(acq_vals)\n    best_idx = torch.argmax(acq_vals)\n    new_x = heldout_inputs[best_idx].unsqueeze(-2)  # add batch dimension\n    new_obj = heldout_outputs[best_idx].unsqueeze(-1) # add output dimension\n\n    # Delete the selected input and value from the heldout set.\n    heldout_inputs = torch.cat((heldout_inputs[:best_idx], heldout_inputs[best_idx+1:]), axis=0)\n    heldout_outputs = torch.cat((heldout_outputs[:best_idx], heldout_outputs[best_idx+1:]), axis=0)\n\n    return new_x, new_obj, heldout_inputs, heldout_outputs\n\ndef update_random_observations(best_random, heldout_inputs, heldout_outputs):\n    \"\"\"Simulates a random policy by taking the current list of best values observed randomly,\n       drawing a new random point from the heldout set, observing its value, and updating the list.\n\n       Args:\n           best_random: List of best random values observed so far\n           heldout_inputs: Tensor of inputs\n           heldout_outputs: Tensor of output values\n\n       Returns:\n           best_random, float specifying the objective function value.\n    \"\"\"\n\n    # Take a random sample by permuting the indices and selecting the first element\n    index = torch.randperm(len(heldout_outputs))[0]\n    next_random_best = heldout_outputs[index]\n    best_random.append(max(best_random[-1], next_random_best))\n\n    # Delete the selected input and value from the heldout set\n    heldout_inputs = torch.cat((heldout_inputs[:index], heldout_inputs[index+1:]), axis=0)\n    heldout_outputs = torch.cat((heldout_outputs[:index], heldout_outputs[index+1:]), axis=0)\n\n    return best_random, heldout_inputs, heldout_outputs",
      "names": [
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 37,
          "end_lineno": 37,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 37,
          "end_lineno": 37,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 41,
          "end_lineno": 41,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "argmax"
          ],
          "code_str": "torch.argmax",
          "lineno": 42,
          "end_lineno": 42,
          "context": "none",
          "resolved_location": "torch.argmax"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 47,
          "end_lineno": 47,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 48,
          "end_lineno": 48,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 66,
          "end_lineno": 66,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "torch",
            "randperm"
          ],
          "code_str": "torch.randperm",
          "lineno": 66,
          "end_lineno": 66,
          "context": "none",
          "resolved_location": "torch.randperm"
        },
        {
          "import_components": [
            "max"
          ],
          "code_str": "max",
          "lineno": 68,
          "end_lineno": 68,
          "context": "none",
          "resolved_location": "max"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 71,
          "end_lineno": 71,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 72,
          "end_lineno": 72,
          "context": "none",
          "resolved_location": "torch.cat"
        }
      ],
      "example": {
        "document": "notebooks/preferential_bayesian_optimisation",
        "ref_id": "Preferential-Bayesian-Optimisation",
        "headings": [
          "Preferential Bayesian Optimisation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Load the dataset and featurise the molecules\"\"\"\n\nloader = MolPropLoader()\nloader.load_benchmark(\"Photoswitch\")\n\n# We use the fragprints representations (a concatenation of Morgan fingerprints and RDKit fragment features)\n\nloader.featurize('ecfp_fragprints')\nX = loader.features\ny = loader.labels",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "featurize"
          ],
          "code_str": "loader.featurize",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.featurize"
        }
      ],
      "example": {
        "document": "notebooks/preferential_bayesian_optimisation",
        "ref_id": "Preferential-Bayesian-Optimisation",
        "headings": [
          "Preferential Bayesian Optimisation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Preferential Bayesian optimisation loop\"\"\"\n\n# Experiment parameters\nN_TRIALS = 20\nholdout_set_size = 0.75\nN_ITERS = 20\nNOISE = 0.0\nverbose = False\nm = 100\n\nbest_observed_all_eubo, best_random_all = [], []\n\n# Average over multiple random trials (each trial splits the initial training set for the GP in a random manner)\nfor trial in range(1, N_TRIALS + 1):\n\n    # Set seeds for reproducbibility. Some numerical instability with EUBO for some runs\n    torch.manual_seed(trial+10)\n    np.random.seed(trial+10)\n\n    print(f'\\nTrial {trial:>2} of {N_TRIALS}', end=\"\")\n    best_observed_eubo, best_random = [], []\n\n    # Generate initial training data and initialize model\n    train_x_eubo, heldout_x_eubo, train_y_eubo, heldout_y_eubo = train_test_split(X, y, test_size=holdout_set_size, random_state=trial)\n    best_observed_value_eubo = torch.tensor(np.max(train_y_eubo))\n    # Set the previous winner for the first round\n    previous_winner = torch.tensor(train_x_eubo[np.argmax(train_y_eubo)]).unsqueeze(-2)\n\n    # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n    train_x_eubo = torch.tensor(train_x_eubo.astype(np.float64))\n    heldout_x_eubo = torch.tensor(heldout_x_eubo.astype(np.float64))\n    train_y_eubo = torch.tensor(train_y_eubo.astype(np.float64))\n    heldout_y_eubo = torch.tensor(heldout_y_eubo.astype(np.float64))\n    train_comp = generate_comparisons(train_y_eubo.squeeze(-1), m, noise=NOISE)\n\n    # The initial heldout set is the same for random search\n    heldout_x_random = heldout_x_eubo\n    heldout_y_random = heldout_y_eubo\n\n    mll_eubo, model_eubo = initialize_model(train_x_eubo, train_comp)\n\n    best_observed_eubo.append(best_observed_value_eubo)\n    best_random.append(best_observed_value_eubo)\n\n    # run N_ITERS rounds of BayesOpt after the initial random batch\n    for iteration in range(1, N_ITERS + 1):\n        t0 = time.time()\n\n        # fit the model\n        fit_gpytorch_model(mll_eubo)\n\n        # Use EUBO acquisition function\n        acq_func = AnalyticExpectedUtilityOfBestOption(pref_model=model_eubo, previous_winner=previous_winner)\n\n        try:\n            new_x_eubo, new_obj_eubo, heldout_x_eubo, heldout_y_eubo = optimize_acqf_and_get_observation(acq_func, heldout_x_eubo, heldout_y_eubo)\n        except:\n            break\n        # Update training points\n        train_x_eubo = torch.cat([train_x_eubo, new_x_eubo])\n        train_y_eubo = torch.cat([train_y_eubo, new_obj_eubo])\n        previous_winner = new_x_eubo\n\n        next_comps = generate_comparisons(train_y_eubo.squeeze(-1), n_comp=m, noise=NOISE)\n        train_comp = torch.cat([train_comp, next_comps])\n\n        # update random search progress\n        best_random, heldout_x_random, heldout_y_random = update_random_observations(best_random,\n                                                                                     heldout_inputs=heldout_x_random,\n                                                                                     heldout_outputs=heldout_y_random)\n\n        best_value_eubo = torch.max(new_obj_eubo, best_observed_eubo[-1])\n        best_observed_eubo.append(best_value_eubo)\n\n        # reinitialise the model so it is ready for fitting on the next iteration\n        # use the current state_dict to speed up fitting\n        mll_eubo, model_eubo = initialize_model(\n            train_x_eubo,\n            train_comp,\n            model_eubo.state_dict(),\n        )\n\n        t1 = time.time()\n\n        if verbose:\n            print(\n                f\"\\nBatch {iteration:>2}: best value (random, qEUBO) = \"\n                f\"({max(best_random):>4.2f}, {best_value_eubo:>4.2f}), \"\n                f\"time = {t1 - t0:>4.2f}.\", end=\"\"\n            )\n        else:\n            print(\".\", end=\"\")\n\n    best_observed_all_eubo.append(best_observed_eubo)\n    best_random_all.append(best_random)",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "torch",
            "manual_seed"
          ],
          "code_str": "torch.manual_seed",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "torch.manual_seed"
        },
        {
          "import_components": [
            "numpy",
            "random",
            "seed"
          ],
          "code_str": "np.random.seed",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "numpy.random.seed"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "argmax"
          ],
          "code_str": "np.argmax",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "numpy.argmax"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 31,
          "end_lineno": 31,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 46,
          "end_lineno": 46,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "time",
            "time"
          ],
          "code_str": "time.time",
          "lineno": 47,
          "end_lineno": 47,
          "context": "none",
          "resolved_location": "time.time"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 60,
          "end_lineno": 60,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 61,
          "end_lineno": 61,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 65,
          "end_lineno": 65,
          "context": "none",
          "resolved_location": "torch.cat"
        },
        {
          "import_components": [
            "torch",
            "max"
          ],
          "code_str": "torch.max",
          "lineno": 72,
          "end_lineno": 72,
          "context": "none",
          "resolved_location": "torch.max"
        },
        {
          "import_components": [
            "time",
            "time"
          ],
          "code_str": "time.time",
          "lineno": 83,
          "end_lineno": 83,
          "context": "none",
          "resolved_location": "time.time"
        },
        {
          "import_components": [
            "max"
          ],
          "code_str": "max",
          "lineno": 88,
          "end_lineno": 88,
          "context": "none",
          "resolved_location": "max"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 86,
          "end_lineno": 86,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 92,
          "end_lineno": 92,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/preferential_bayesian_optimisation",
        "ref_id": "Preferential-Bayesian-Optimisation",
        "headings": [
          "Preferential Bayesian Optimisation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Plots the results\"\"\"\n\n# Define a confidence interval function for plotting.\ndef ci(y):\n    return 1.0 * y.std(axis=0) / np.sqrt(N_TRIALS)\n\niters = np.arange(N_ITERS + 1)\n# Use first n trials without failure due to numerical errors in EUBO. Can judge from output above\u00df\nn = 8\ny_eubo = torch.tensor(best_observed_all_eubo[0:n])\ny_rnd = torch.tensor(best_random_all[0:n])\n\ny_rnd_mean = y_rnd.mean(axis=0)\ny_eubo_mean = y_eubo.mean(axis=0)\n\nlower_rnd = y_rnd_mean - ci(y_rnd)\nupper_rnd = y_rnd_mean + ci(y_rnd)\nlower_eubo = y_eubo_mean - ci(y_eubo)\nupper_eubo = y_eubo_mean + ci(y_eubo)\n\nplt.plot(iters, y_rnd_mean, label='Random search', color='tab:green')\nplt.fill_between(iters, lower_rnd, upper_rnd, alpha=0.2, color='tab:green')\nplt.plot(iters, y_eubo_mean, label='EUBO', color='tab:red')\nplt.fill_between(iters, lower_eubo, upper_eubo, alpha=0.2, color='tab:red')\nplt.xlabel('Number of Iterations')\nplt.ylabel('Best Objective Value')\nplt.legend(loc=\"upper left\")\nplt.xticks(list(np.arange(0, 21, 2)))\nplt.show()",
      "names": [
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "fill_between"
          ],
          "code_str": "plt.fill_between",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.fill_between"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "fill_between"
          ],
          "code_str": "plt.fill_between",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.fill_between"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xticks"
          ],
          "code_str": "plt.xticks",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "notebooks/preferential_bayesian_optimisation",
        "ref_id": "Preferential-Bayesian-Optimisation",
        "headings": [
          "Preferential Bayesian Optimisation"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/protein_fitness_prediction_bag_of_amino_acids": [
    {
      "source": "\"\"\"Imports\"\"\"\n\n# Turn off Graphein warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom botorch import fit_gpytorch_model\nfrom botorch.models import SingleTaskGP\nfrom botorch.models.transforms import Normalize, Standardize\nfrom botorch.models.fully_bayesian import MIN_INFERRED_NOISE_LEVEL\nimport gpytorch\nfrom gpytorch.constraints import GreaterThan\nfrom gpytorch.kernels import ScaleKernel\nfrom gpytorch.likelihoods import GaussianLikelihood\nfrom gpytorch.mlls import ExactMarginalLogLikelihood\nfrom gpytorch.priors import GammaPrior\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nimport torch\n\nfrom gauche.dataloader.data_utils import transform_data\nfrom gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 17,
          "end_lineno": 17,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 18,
          "end_lineno": 18,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 19,
          "end_lineno": 19,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "sklearn",
            "feature_extraction",
            "text"
          ],
          "code_str": "sklearn.feature_extraction.text",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_from",
          "resolved_location": "sklearn.feature_extraction.text"
        },
        {
          "import_components": [
            "sklearn",
            "feature_extraction",
            "text",
            "CountVectorizer"
          ],
          "code_str": "CountVectorizer",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_target",
          "resolved_location": "sklearn.feature_extraction.text.CountVectorizer"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "sklearn",
            "metrics"
          ],
          "code_str": "sklearn.metrics",
          "lineno": 22,
          "end_lineno": 22,
          "context": "import_from",
          "resolved_location": "sklearn.metrics"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 22,
          "end_lineno": 22,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 22,
          "end_lineno": 22,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 22,
          "end_lineno": 22,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 23,
          "end_lineno": 23,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils"
          ],
          "code_str": "gauche.dataloader.data_utils",
          "lineno": 25,
          "end_lineno": 25,
          "context": "import_from",
          "resolved_location": "gauche.dataloader.data_utils"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 25,
          "end_lineno": 25,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel"
          ],
          "code_str": "gauche.kernels.fingerprint_kernels.tanimoto_kernel",
          "lineno": 26,
          "end_lineno": 26,
          "context": "import_from",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 26,
          "end_lineno": 26,
          "context": "import_target",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_bag_of_amino_acids",
        "ref_id": "GP-Regression-on-Protein-Sequences:-Bag-of-Amino-Acids",
        "headings": [
          "GP Regression on Protein Sequences: Bag of Amino Acids"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"CPU/GPU\"\"\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntkwargs = {\"dtype\": torch.float, \"device\": device}\nprint(tkwargs)",
      "names": [
        {
          "import_components": [
            "torch",
            "cuda",
            "is_available"
          ],
          "code_str": "torch.cuda.is_available",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "torch.cuda.is_available"
        },
        {
          "import_components": [
            "torch",
            "device"
          ],
          "code_str": "torch.device",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "torch.device"
        },
        {
          "import_components": [
            "torch",
            "device",
            "()"
          ],
          "code_str": "device",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "torch.device"
        },
        {
          "import_components": [
            "torch",
            "device",
            "()"
          ],
          "code_str": "device",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "torch.device"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_bag_of_amino_acids",
        "ref_id": "GP-Regression-on-Protein-Sequences:-Bag-of-Amino-Acids",
        "headings": [
          "GP Regression on Protein Sequences: Bag of Amino Acids"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Auxiliary function to calculate bag of character representation of a protein string\"\"\"\n\ndef bag_of_amino_acids(sequences, max_ngram=5):\n    \"\"\"Compute the bag of amino acids representation of protein sequences.\n\n    Args:\n        sequences: List of Str representing the protein sequences\n        max_ngram: Int specifying the maximum number of n-grams to consider\n\n    Returns:\n        NumPy array of counts for each n-gram present in the protein sequences\n    \"\"\"\n\n    # extract bag of characters (boc) representation from strings\n    cv = CountVectorizer(\n        ngram_range=(1, max_ngram), analyzer=\"char\", lowercase=False\n    )\n    return cv.fit_transform(sequences).toarray()",
      "names": [
        {
          "import_components": [
            "sklearn",
            "feature_extraction",
            "text",
            "CountVectorizer"
          ],
          "code_str": "CountVectorizer",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "sklearn.feature_extraction.text.CountVectorizer"
        },
        {
          "import_components": [
            "sklearn",
            "feature_extraction",
            "text",
            "CountVectorizer",
            "()"
          ],
          "code_str": "cv",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "sklearn.feature_extraction.text.CountVectorizer"
        },
        {
          "import_components": [
            "sklearn",
            "feature_extraction",
            "text",
            "CountVectorizer",
            "()",
            "fit_transform"
          ],
          "code_str": "cv.fit_transform",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "sklearn.feature_extraction.text.CountVectorizer.fit_transform"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_bag_of_amino_acids",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Bag of Amino Acids",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Load the petase dataset\"\"\"\n\nimport sys\nsys.path.append('..')\n\ndf = pd.read_csv('../gauche/datasets/proteins/petase_151_mutants.csv')\nsequences = df['sequence'].to_list()\nX = bag_of_amino_acids(sequences) # process to bag of amino acids\ny = df['fitness'].to_numpy().reshape(-1, 1)\nprint(f'len(sequences) {len(sequences)} | len(targets) {len(y)}')",
      "names": [
        {
          "import_components": [
            "sys"
          ],
          "code_str": "sys",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "sys"
        },
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_bag_of_amino_acids",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Bag of Amino Acids",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Regression experiments parameters, number of random splits and split size\"\"\"\n\nn_trials = 20\ntest_set_size = 0.2",
      "names": [],
      "example": {
        "document": "notebooks/protein_fitness_prediction_bag_of_amino_acids",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Bag of Amino Acids",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"We define our GP model using the Tanimoto kernel.\"\"\"\n\nclass ExactGPModel(gpytorch.models.ExactGP):\n    def __init__(self, train_x, train_y, likelihood):\n        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n        self.mean_module = gpytorch.means.ConstantMean()\n        self.covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel())\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "fingerprint_kernels",
            "tanimoto_kernel",
            "TanimotoKernel"
          ],
          "code_str": "TanimotoKernel",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "gauche.kernels.fingerprint_kernels.tanimoto_kernel.TanimotoKernel"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_bag_of_amino_acids",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Bag of Amino Acids",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "def evaluate_model(X, y):\n    \"\"\"\n    Helper function for model evaluation\n\n    X: Inputs\n    y: Outputs\n    \"\"\"\n\n    # initialise performance metric lists\n    r2_list = []\n    rmse_list = []\n    mae_list = []\n\n    # We pre-allocate array for plotting confidence-error curves\n\n    _, _, _, y_test = train_test_split(X, y, test_size=test_set_size)  # To get test set size\n    n_test = len(y_test)\n\n    mae_confidence_list = np.zeros((n_trials, n_test))\n\n    print('\\nBeginning training loop...')\n\n    for i in range(0, n_trials):\n\n        print(f'Starting trial {i}')\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n\n        #  We standardise the outputs but leave the inputs unchanged\n        _, y_train, _, y_test, y_scaler = transform_data(X_train, y_train, X_test, y_test)\n\n        # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n        X_train = torch.tensor(X_train.astype(np.float64))\n        X_test = torch.tensor(X_test.astype(np.float64))\n        y_train = torch.tensor(y_train).flatten()\n        y_test = torch.tensor(y_test).flatten()\n\n        # initialise GP likelihood and model\n        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n        model = ExactGPModel(X_train, y_train, likelihood)\n\n        # Find optimal model hyperparameters\n        # \"Loss\" for GPs - the marginal log likelihood\n        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n\n        # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n        fit_gpytorch_model(mll)\n\n        # Get into evaluation (predictive posterior) mode\n        model.eval()\n        likelihood.eval()\n\n        # mean and variance GP prediction\n        f_pred = model(X_test)\n\n        y_pred = f_pred.mean\n        y_var = f_pred.variance\n\n        # Transform back to real data space to compute metrics and detach gradients. Must unsqueeze dimension\n        # to make compatible with inverse_transform in scikit-learn version > 1\n        y_pred = y_scaler.inverse_transform(y_pred.detach().unsqueeze(dim=1))\n        y_test = y_scaler.inverse_transform(y_test.detach().unsqueeze(dim=1))\n\n        # Compute scores for confidence curve plotting.\n\n        ranked_confidence_list = np.argsort(y_var.detach(), axis=0).flatten()\n\n        for k in range(len(y_test)):\n\n            # Construct the MAE error for each level of confidence\n\n            conf = ranked_confidence_list[0:k+1]\n            mae = mean_absolute_error(y_test[conf], y_pred[conf])\n            mae_confidence_list[i, k] = mae\n\n        # Output Standardised RMSE and RMSE on Train Set\n        y_train = y_train.detach()\n        y_pred_train = model(X_train).mean.detach()\n        train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n        train_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(y_train.unsqueeze(dim=1)),\n                                                y_scaler.inverse_transform(y_pred_train.unsqueeze(dim=1))))\n\n        # Compute R^2, RMSE and MAE on Test set\n        score = r2_score(y_test, y_pred)\n        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n        mae = mean_absolute_error(y_test, y_pred)\n\n        r2_list.append(score)\n        rmse_list.append(rmse)\n        mae_list.append(mae)\n\n    r2_list = np.array(r2_list)\n    rmse_list = np.array(rmse_list)\n    mae_list = np.array(mae_list)\n\n    print(\"\\nmean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list)/np.sqrt(len(r2_list))))\n    print(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list)/np.sqrt(len(rmse_list))))\n    print(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list)/np.sqrt(len(mae_list))))\n\n    # Plot confidence-error curves\n\n    # 1e-14 instead of 0 to for numerical reasons!\n    confidence_percentiles = np.arange(1e-14, 100, 100/len(y_test))\n\n    # We plot the Mean-absolute error confidence-error curves\n\n    mae_mean = np.mean(mae_confidence_list, axis=0)\n    mae_std = np.std(mae_confidence_list, axis=0)\n\n    mae_mean = np.flip(mae_mean)\n    mae_std = np.flip(mae_std)\n\n    # 1 sigma errorbars\n\n    lower = mae_mean - mae_std\n    upper = mae_mean + mae_std\n\n    warnings.filterwarnings(\"ignore\")\n\n    plt.plot(confidence_percentiles, mae_mean, label='mean')\n    plt.fill_between(confidence_percentiles, lower, upper, alpha=0.2)\n    plt.xlabel('Confidence Percentile')\n    plt.ylabel('Melting Point (Celcius)')\n    plt.ylim([0, np.max(upper) + 1])\n    plt.xlim([0, 100 * ((len(y_test) - 1) / len(y_test))])\n    plt.yticks(np.arange(0, np.max(upper) + 1, 5.0))\n    plt.show()",
      "names": [
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 19,
          "end_lineno": 19,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 27,
          "end_lineno": 27,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 35,
          "end_lineno": 35,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "argsort"
          ],
          "code_str": "np.argsort",
          "lineno": 66,
          "end_lineno": 66,
          "context": "none",
          "resolved_location": "numpy.argsort"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 68,
          "end_lineno": 68,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 68,
          "end_lineno": 68,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 73,
          "end_lineno": 73,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 79,
          "end_lineno": 79,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 79,
          "end_lineno": 79,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 80,
          "end_lineno": 80,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 80,
          "end_lineno": 80,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 84,
          "end_lineno": 84,
          "context": "none",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 85,
          "end_lineno": 85,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 85,
          "end_lineno": 85,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 86,
          "end_lineno": 86,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 92,
          "end_lineno": 92,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 93,
          "end_lineno": 93,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 94,
          "end_lineno": 94,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 96,
          "end_lineno": 96,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 96,
          "end_lineno": 96,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 96,
          "end_lineno": 96,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 96,
          "end_lineno": 96,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 96,
          "end_lineno": 96,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 97,
          "end_lineno": 97,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 97,
          "end_lineno": 97,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 97,
          "end_lineno": 97,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 97,
          "end_lineno": 97,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 97,
          "end_lineno": 97,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 98,
          "end_lineno": 98,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 98,
          "end_lineno": 98,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 98,
          "end_lineno": 98,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 98,
          "end_lineno": 98,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 98,
          "end_lineno": 98,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 103,
          "end_lineno": 103,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 103,
          "end_lineno": 103,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 107,
          "end_lineno": 107,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 108,
          "end_lineno": 108,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 110,
          "end_lineno": 110,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 111,
          "end_lineno": 111,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 118,
          "end_lineno": 118,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 120,
          "end_lineno": 120,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "fill_between"
          ],
          "code_str": "plt.fill_between",
          "lineno": 121,
          "end_lineno": 121,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.fill_between"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 122,
          "end_lineno": 122,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 123,
          "end_lineno": 123,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 124,
          "end_lineno": 124,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 124,
          "end_lineno": 124,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 125,
          "end_lineno": 125,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 125,
          "end_lineno": 125,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 125,
          "end_lineno": 125,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 126,
          "end_lineno": 126,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 126,
          "end_lineno": 126,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "yticks"
          ],
          "code_str": "plt.yticks",
          "lineno": 126,
          "end_lineno": 126,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.yticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 127,
          "end_lineno": 127,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_bag_of_amino_acids",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Bag of Amino Acids",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "evaluate_model(X, y)",
      "names": [],
      "example": {
        "document": "notebooks/protein_fitness_prediction_bag_of_amino_acids",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Bag of Amino Acids",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/protein_fitness_prediction_ssk_gp": [
    {
      "source": "\"\"\"Imports\"\"\"\n\n# Turn off Graphein warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom botorch import fit_gpytorch_model\nfrom botorch.models import SingleTaskGP\nfrom botorch.models.transforms import Normalize, Standardize\nfrom botorch.models.fully_bayesian import MIN_INFERRED_NOISE_LEVEL\nfrom gpytorch.constraints import GreaterThan\nfrom gpytorch.kernels import ScaleKernel\nfrom gpytorch.likelihoods import GaussianLikelihood\nfrom gpytorch.mlls import ExactMarginalLogLikelihood\nfrom gpytorch.priors import GammaPrior\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_absolute_error\nimport torch\n\nfrom gauche.dataloader.data_utils import transform_data\nfrom gauche.kernels.string_kernels.sskkernel import pad, encode_string, build_one_hot, SubsequenceStringKernel",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 16,
          "end_lineno": 16,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 17,
          "end_lineno": 17,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 18,
          "end_lineno": 18,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 19,
          "end_lineno": 19,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 19,
          "end_lineno": 19,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "sklearn",
            "metrics"
          ],
          "code_str": "sklearn.metrics",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_from",
          "resolved_location": "sklearn.metrics"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 21,
          "end_lineno": 21,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils"
          ],
          "code_str": "gauche.dataloader.data_utils",
          "lineno": 23,
          "end_lineno": 23,
          "context": "import_from",
          "resolved_location": "gauche.dataloader.data_utils"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 23,
          "end_lineno": 23,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "string_kernels",
            "sskkernel",
            "SubsequenceStringKernel"
          ],
          "code_str": "SubsequenceStringKernel",
          "lineno": 24,
          "end_lineno": 24,
          "context": "import_target",
          "resolved_location": "gauche.kernels.string_kernels.sskkernel.SubsequenceStringKernel"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "GP-Regression-on-Protein-Sequences:-Subsequence-String-Kernel",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"CPU/GPU\"\"\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntkwargs = {\"dtype\": torch.float, \"device\": device}\nprint(tkwargs)",
      "names": [
        {
          "import_components": [
            "torch",
            "cuda",
            "is_available"
          ],
          "code_str": "torch.cuda.is_available",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "torch.cuda.is_available"
        },
        {
          "import_components": [
            "torch",
            "device"
          ],
          "code_str": "torch.device",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "torch.device"
        },
        {
          "import_components": [
            "torch",
            "device",
            "()"
          ],
          "code_str": "device",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "torch.device"
        },
        {
          "import_components": [
            "torch",
            "device",
            "()"
          ],
          "code_str": "device",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "torch.device"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "GP-Regression-on-Protein-Sequences:-Subsequence-String-Kernel",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Regression experiments parameters, number of random splits and split size\"\"\"\n\nn_trials = 20\ntest_set_size = 0.2",
      "names": [],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Load the petase dataset\"\"\"\n\nimport sys\nsys.path.append('..')\n\ndf = pd.read_csv('../gauche/datasets/proteins/petase_151_mutants.csv')\nx = df['sequence'].to_list()\ny = df['fitness'].to_numpy().reshape(-1, 1)\nprint(f'len(sequences) {len(x)} | len(targets) {len(y)}')",
      "names": [
        {
          "import_components": [
            "sys"
          ],
          "code_str": "sys",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "sys"
        },
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Compute the required sequence properties for modelling with the SSK kernel GP.\"\"\"\n\nmaxlen = np.max([len(seq) for seq in x])\n# get alphabet of characters used in candidate set (to init SSK)\nalphabet = list({l for word in x for l in word})\nprint(f'alphabet \\n {alphabet} \\n length of alphabet {len(alphabet)}')\nprint(f'maxlen {maxlen}')",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "The-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel",
          "The Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Process the inputs x to the string kernel GPs\"\"\"\n\n# Compute one-hot encodings and an integer index for the given amino acid alphabet\nembds, index = build_one_hot(alphabet)\nembds = embds.to(**tkwargs)\n\n# Process the string inputs to the SSK model\nx = torch.cat([pad(encode_string(seq, index), maxlen).unsqueeze(0) for seq in x], dim=0)",
      "names": [
        {
          "import_components": [
            "torch",
            "cat"
          ],
          "code_str": "torch.cat",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "torch.cat"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "GP-Regression-on-the-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel",
          "GP Regression on the Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Compute the train/test split.\"\"\"\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_set_size, random_state=0)\nX_train = X_train.to(**tkwargs)\nX_test = X_test.to(**tkwargs)\ny_train = torch.tensor(y_train, **tkwargs)\ny_test = torch.tensor(y_test, **tkwargs)",
      "names": [
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "torch.tensor"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "GP-Regression-on-the-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel",
          "GP Regression on the Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Intialize and fit the models\"\"\"\n\n# Likelihood function\nlikelihood = GaussianLikelihood(\n    noise_prior=GammaPrior(torch.tensor(0.9, **tkwargs), torch.tensor(10.0, **tkwargs)),\n    noise_constraint=GreaterThan(MIN_INFERRED_NOISE_LEVEL),\n)\n\n# Covariance function\ncovar_module = ScaleKernel(SubsequenceStringKernel(embds, index, alphabet, maxlen, **tkwargs))\n\n\nssk_gp_model = SingleTaskGP(\n    train_X=X_train,\n    train_Y=y_train,\n    outcome_transform=Standardize(1),\n    likelihood=likelihood,\n    covar_module=covar_module,\n)\n\nmll = ExactMarginalLogLikelihood(model=ssk_gp_model, likelihood=ssk_gp_model.likelihood)\n# ideally we can optimize over the kernel hyper-parameters of the string kernel\n# however, the gpu memory usage in batch (GPU) version of the kernel is quite high\n# while the standard non-batch version is relatively slow for kernel evaluation.\n# Nevertheless, the kernel is very robust to choices of the different hypers.\nmll.model.covar_module.base_kernel.raw_order_coefs.requires_grad = False\nmll.model.covar_module.base_kernel.raw_match_decay.requires_grad = False\nmll.model.covar_module.base_kernel.raw_gap_decay.requires_grad = False\n\nfit_gpytorch_model(mll)",
      "names": [
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "gauche",
            "kernels",
            "string_kernels",
            "sskkernel",
            "SubsequenceStringKernel"
          ],
          "code_str": "SubsequenceStringKernel",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "gauche.kernels.string_kernels.sskkernel.SubsequenceStringKernel"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "GP-Regression-on-the-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel",
          "GP Regression on the Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Evaluate the trained model.\"\"\"\n\nposterior = ssk_gp_model.posterior(X_test)\nposterior_mean = posterior.mean.cpu().detach()\nposterior_std = torch.sqrt(posterior.variance.cpu().detach())\n\nr2 = r2_score(y_test, posterior_mean.numpy())\nprint(mean_absolute_error(posterior_mean.squeeze(1), y_test.cpu().detach().squeeze(1)))",
      "names": [
        {
          "import_components": [
            "torch",
            "sqrt"
          ],
          "code_str": "torch.sqrt",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "torch.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "GP-Regression-on-the-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel",
          "GP Regression on the Petase Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "\"\"\"Plot the R^2\"\"\"\n\nfig, ax = plt.subplots(1, 2, figsize = (16, 6))\nax = ax.reshape(-1)\n\nax.scatter(y_test, posterior_mean.numpy())\nax.set_title(f'Test set $R^2 = {r2:.2f}$')\nax.plot(np.unique(y_test), np.poly1d(np.polyfit(y_test, posterior_mean.numpy(), 1)(np.unique(y_test)), color='k', linewidth=0.4))",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        },
        {
          "import_components": [
            "numpy",
            "unique"
          ],
          "code_str": "np.unique",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.unique"
        },
        {
          "import_components": [
            "numpy",
            "unique"
          ],
          "code_str": "np.unique",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.unique"
        },
        {
          "import_components": [
            "numpy",
            "polyfit"
          ],
          "code_str": "np.polyfit",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.polyfit"
        },
        {
          "import_components": [
            "numpy",
            "poly1d"
          ],
          "code_str": "np.poly1d",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "numpy.poly1d"
        }
      ],
      "example": {
        "document": "notebooks/protein_fitness_prediction_ssk_gp",
        "ref_id": "GP-Regression-on-the-Petase-Dataset",
        "headings": [
          "GP Regression on Protein Sequences: Subsequence String Kernel",
          "GP Regression on the Petase Dataset"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/sparse_gp_regression_for_big_molecular_data": [
    {
      "source": "# Imports\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n\nimport time\n\nfrom botorch import fit_gpytorch_model\nimport gpytorch\nfrom mordred import Calculator, descriptors\nimport numpy as np\nfrom rdkit import Chem\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nimport torch\n\nfrom gauche.dataloader import MolPropLoader\nfrom gauche.dataloader.data_utils import transform_data",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "time"
          ],
          "code_str": "time",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "time"
        },
        {
          "import_components": [
            "numpy"
          ],
          "code_str": "numpy",
          "lineno": 11,
          "end_lineno": 11,
          "context": "import_target",
          "resolved_location": "numpy"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition"
          ],
          "code_str": "sklearn.decomposition",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_from",
          "resolved_location": "sklearn.decomposition"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition",
            "PCA"
          ],
          "code_str": "PCA",
          "lineno": 13,
          "end_lineno": 13,
          "context": "import_target",
          "resolved_location": "sklearn.decomposition._pca.PCA"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection"
          ],
          "code_str": "sklearn.model_selection",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_from",
          "resolved_location": "sklearn.model_selection"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 14,
          "end_lineno": 14,
          "context": "import_target",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "sklearn",
            "metrics"
          ],
          "code_str": "sklearn.metrics",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_from",
          "resolved_location": "sklearn.metrics"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 15,
          "end_lineno": 15,
          "context": "import_target",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing"
          ],
          "code_str": "sklearn.preprocessing",
          "lineno": 16,
          "end_lineno": 16,
          "context": "import_from",
          "resolved_location": "sklearn.preprocessing"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing",
            "StandardScaler"
          ],
          "code_str": "StandardScaler",
          "lineno": 16,
          "end_lineno": 16,
          "context": "import_target",
          "resolved_location": "sklearn.preprocessing._data.StandardScaler"
        },
        {
          "import_components": [
            "torch"
          ],
          "code_str": "torch",
          "lineno": 17,
          "end_lineno": 17,
          "context": "import_target",
          "resolved_location": "torch"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 19,
          "end_lineno": 19,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils"
          ],
          "code_str": "gauche.dataloader.data_utils",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_from",
          "resolved_location": "gauche.dataloader.data_utils"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 20,
          "end_lineno": 20,
          "context": "import_target",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        }
      ],
      "example": {
        "document": "notebooks/sparse_gp_regression_for_big_molecular_data",
        "ref_id": "Sparse-GP-Regression-on-Molecules",
        "headings": [
          "Sparse GP Regression on Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# We define our sparse GP model using and inducing point kernel wrapped around the RQ kernel\n\nfrom gpytorch.means import ConstantMean\nfrom gpytorch.kernels import ScaleKernel, InducingPointKernel, RQKernel\nfrom gpytorch.distributions import MultivariateNormal\n\nclass SparseGPModel(gpytorch.models.ExactGP):\n    def __init__(self, train_x, train_y, likelihood):\n        super(SparseGPModel, self).__init__(train_x, train_y, likelihood)\n        self.mean_module = ConstantMean()\n        self.base_covar_module = ScaleKernel(RQKernel())\n        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=train_x[:100, :].clone(), likelihood=likelihood)\n\n    def forward(self, x):\n        mean_x = self.mean_module(x)\n        covar_x = self.covar_module(x)\n        return MultivariateNormal(mean_x, covar_x)",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "notebooks/sparse_gp_regression_for_big_molecular_data",
        "ref_id": "Sparse-GP-Regression-on-Molecules",
        "headings": [
          "Sparse GP Regression on Molecules"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Regression experiments parameters, number of random splits and split size\n\nn_trials = 20\ntest_set_size = 0.2",
      "names": [],
      "example": {
        "document": "notebooks/sparse_gp_regression_for_big_molecular_data",
        "ref_id": "Sparse-GP-Regression-on-the-Lipophilicity-Dataset",
        "headings": [
          "Sparse GP Regression on Molecules",
          "Sparse GP Regression on the Lipophilicity Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "# Load the Lipophilicity dataset\n\nloader = MolPropLoader()\nloader.load_benchmark(\"Lipophilicity\")\n\n# Mordred descriptor computation is expensive\ncalc = Calculator(descriptors, ignore_3D=False)\nmols = [Chem.MolFromSmiles(smi) for smi in loader.features]\nt0 = time.time()\nX_mordred = [calc(mol) for mol in mols]\nt1 = time.time()\nprint(f'Mordred descriptor computation takes {t1 - t0} seconds')\nX_mordred = np.array(X_mordred).astype(np.float64)\ny = loader.labels\n\n\"\"\"Collect nan indices\"\"\"\n\nnan_dims = []\n\nfor i in range(len(X_mordred)):\n    nan_indices = list(np.where(np.isnan(X_mordred[i, :]))[0])\n    for dim in nan_indices:\n        if dim not in nan_dims:\n            nan_dims.append(dim)\n\nX_mordred = np.delete(X_mordred, nan_dims, axis=1)",
      "names": [
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader"
          ],
          "code_str": "MolPropLoader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()"
          ],
          "code_str": "loader",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "MolPropLoader",
            "()",
            "load_benchmark"
          ],
          "code_str": "loader.load_benchmark",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "gauche.dataloader.molprop_loader.MolPropLoader.load_benchmark"
        },
        {
          "import_components": [
            "time",
            "time"
          ],
          "code_str": "time.time",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "time.time"
        },
        {
          "import_components": [
            "time",
            "time"
          ],
          "code_str": "time.time",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "time.time"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 20,
          "end_lineno": 20,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "numpy",
            "isnan"
          ],
          "code_str": "np.isnan",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "numpy.isnan"
        },
        {
          "import_components": [
            "numpy",
            "where"
          ],
          "code_str": "np.where",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "numpy.where"
        },
        {
          "import_components": [
            "list"
          ],
          "code_str": "list",
          "lineno": 21,
          "end_lineno": 21,
          "context": "none",
          "resolved_location": "list"
        },
        {
          "import_components": [
            "numpy",
            "delete"
          ],
          "code_str": "np.delete",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "numpy.delete"
        }
      ],
      "example": {
        "document": "notebooks/sparse_gp_regression_for_big_molecular_data",
        "ref_id": "Sparse-GP-Regression-on-the-Lipophilicity-Dataset",
        "headings": [
          "Sparse GP Regression on Molecules",
          "Sparse GP Regression on the Lipophilicity Dataset"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\") # Turn off GPyTorch warnings\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n\ndef evaluate_model(X, y):\n    \"\"\"Helper function for model evaluation.\n\n    Args:\n        X: n x d NumPy array of inputs representing molecules\n        y: n x 1 NumPy array of output labels\n    Returns:\n        regression metrics and confidence-error curve plot.\n    \"\"\"\n\n    # initialise performance metric lists\n    r2_list = []\n    rmse_list = []\n    mae_list = []\n\n    # We pre-allocate array for plotting confidence-error curves\n\n    _, _, _, y_test = train_test_split(X, y, test_size=test_set_size)  # To get test set size\n    n_test = len(y_test)\n\n    mae_confidence_list = np.zeros((n_trials, n_test))\n\n    print('\\nBeginning training loop...')\n\n    for i in range(0, n_trials):\n\n        print(f'Starting trial {i}')\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n        pca_mordred = PCA(n_components=51)\n        X_train = pca_mordred.fit_transform(X_train)\n        X_test = pca_mordred.transform(X_test)\n\n        #  We standardise the outputs\n        _, y_train, _, y_test, y_scaler = transform_data(X_train, y_train, X_test, y_test)\n\n        # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n        X_train = torch.tensor(X_train.astype(np.float64))\n        X_test = torch.tensor(X_test.astype(np.float64))\n        y_train = torch.tensor(y_train).flatten()\n        y_test = torch.tensor(y_test).flatten()\n\n        # initialise GP likelihood and model\n        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n        model = SparseGPModel(X_train, y_train, likelihood)\n\n        # Find optimal model hyperparameters\n        # \"Loss\" for GPs - the marginal log likelihood\n        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n\n        # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n        fit_gpytorch_model(mll)\n\n        # Get into evaluation (predictive posterior) mode\n        model.eval()\n        likelihood.eval()\n\n        # mean and variance GP prediction\n        f_pred = model(X_test)\n\n        y_pred = f_pred.mean\n        y_var = f_pred.variance\n\n        # Transform back to real data space to compute metrics and detach gradients. Must unsqueeze dimension\n        # to make compatible with inverse_transform in scikit-learn version > 1\n        y_pred = y_scaler.inverse_transform(y_pred.detach().unsqueeze(dim=1))\n        y_test = y_scaler.inverse_transform(y_test.detach().unsqueeze(dim=1))\n\n        # Compute scores for confidence curve plotting.\n\n        ranked_confidence_list = np.argsort(y_var.detach(), axis=0).flatten()\n\n        for k in range(len(y_test)):\n\n            # Construct the MAE error for each level of confidence\n\n            conf = ranked_confidence_list[0:k+1]\n            mae = mean_absolute_error(y_test[conf], y_pred[conf])\n            mae_confidence_list[i, k] = mae\n\n        # Output Standardised RMSE and RMSE on Train Set\n        y_train = y_train.detach()\n        y_pred_train = model(X_train).mean.detach()\n        train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n        train_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(y_train.unsqueeze(dim=1)),\n                                                y_scaler.inverse_transform(y_pred_train.unsqueeze(dim=1))))\n\n        # Compute R^2, RMSE and MAE on Test set\n        score = r2_score(y_test, y_pred)\n        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n        mae = mean_absolute_error(y_test, y_pred)\n\n        r2_list.append(score)\n        rmse_list.append(rmse)\n        mae_list.append(mae)\n\n    r2_list = np.array(r2_list)\n    rmse_list = np.array(rmse_list)\n    mae_list = np.array(mae_list)\n\n    print(\"\\nmean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list)/np.sqrt(len(r2_list))))\n    print(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list)/np.sqrt(len(rmse_list))))\n    print(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list)/np.sqrt(len(mae_list))))\n\n    # Plot confidence-error curves\n\n    # 1e-14 instead of 0 to for numerical reasons!\n    confidence_percentiles = np.arange(1e-14, 100, 100/len(y_test))\n\n    # We plot the Mean-absolute error confidence-error curves\n\n    mae_mean = np.mean(mae_confidence_list, axis=0)\n    mae_std = np.std(mae_confidence_list, axis=0)\n\n    mae_mean = np.flip(mae_mean)\n    mae_std = np.flip(mae_std)\n\n    # 1 sigma errorbars\n\n    lower = mae_mean - mae_std\n    upper = mae_mean + mae_std\n\n    plt.plot(confidence_percentiles, mae_mean, label='mean')\n    plt.fill_between(confidence_percentiles, lower, upper, alpha=0.2)\n    plt.xlabel('Confidence Percentile')\n    plt.ylabel('MAE (nm)')\n    plt.ylim([0, np.max(upper) + 1])\n    plt.xlim([0, 100 * ((len(y_test) - 1) / len(y_test))])\n    plt.yticks(np.arange(0, np.max(upper) + 1, 5.0))\n    plt.show()\n\n    return rmse_list, mae_list",
      "names": [
        {
          "import_components": [
            "warnings"
          ],
          "code_str": "warnings",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "warnings"
        },
        {
          "import_components": [
            "warnings",
            "filterwarnings"
          ],
          "code_str": "warnings.filterwarnings",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "warnings.filterwarnings"
        },
        {
          "import_components": [
            "matplotlib"
          ],
          "code_str": "matplotlib",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_from",
          "resolved_location": "matplotlib"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 25,
          "end_lineno": 25,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "zeros"
          ],
          "code_str": "np.zeros",
          "lineno": 28,
          "end_lineno": 28,
          "context": "none",
          "resolved_location": "numpy.zeros"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 30,
          "end_lineno": 30,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 34,
          "end_lineno": 34,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "sklearn",
            "model_selection",
            "train_test_split"
          ],
          "code_str": "train_test_split",
          "lineno": 36,
          "end_lineno": 36,
          "context": "none",
          "resolved_location": "sklearn.model_selection.train_test_split"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing",
            "StandardScaler"
          ],
          "code_str": "StandardScaler",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "sklearn.preprocessing._data.StandardScaler"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing",
            "StandardScaler",
            "()"
          ],
          "code_str": "scaler",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "sklearn.preprocessing._data.StandardScaler"
        },
        {
          "import_components": [
            "sklearn",
            "preprocessing",
            "StandardScaler",
            "()",
            "fit_transform"
          ],
          "code_str": "scaler.fit_transform",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "sklearn.base.TransformerMixin.fit_transform"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition",
            "PCA"
          ],
          "code_str": "PCA",
          "lineno": 41,
          "end_lineno": 41,
          "context": "none",
          "resolved_location": "sklearn.decomposition._pca.PCA"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition",
            "PCA",
            "()"
          ],
          "code_str": "pca_mordred",
          "lineno": 41,
          "end_lineno": 41,
          "context": "none",
          "resolved_location": "sklearn.decomposition._pca.PCA"
        },
        {
          "import_components": [
            "sklearn",
            "decomposition",
            "PCA",
            "()",
            "fit_transform"
          ],
          "code_str": "pca_mordred.fit_transform",
          "lineno": 42,
          "end_lineno": 42,
          "context": "none",
          "resolved_location": "sklearn.base.TransformerMixin.fit_transform"
        },
        {
          "import_components": [
            "gauche",
            "dataloader",
            "data_utils",
            "transform_data"
          ],
          "code_str": "transform_data",
          "lineno": 46,
          "end_lineno": 46,
          "context": "none",
          "resolved_location": "gauche.dataloader.data_utils.transform_data"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 49,
          "end_lineno": 49,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 49,
          "end_lineno": 49,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "float64"
          ],
          "code_str": "np.float64",
          "lineno": 50,
          "end_lineno": 50,
          "context": "none",
          "resolved_location": "numpy.float64"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 50,
          "end_lineno": 50,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 51,
          "end_lineno": 51,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "torch",
            "tensor"
          ],
          "code_str": "torch.tensor",
          "lineno": 52,
          "end_lineno": 52,
          "context": "none",
          "resolved_location": "torch.tensor"
        },
        {
          "import_components": [
            "numpy",
            "argsort"
          ],
          "code_str": "np.argsort",
          "lineno": 82,
          "end_lineno": 82,
          "context": "none",
          "resolved_location": "numpy.argsort"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 84,
          "end_lineno": 84,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 84,
          "end_lineno": 84,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 89,
          "end_lineno": 89,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 95,
          "end_lineno": 95,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 95,
          "end_lineno": 95,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 96,
          "end_lineno": 96,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 96,
          "end_lineno": 96,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "r2_score"
          ],
          "code_str": "r2_score",
          "lineno": 100,
          "end_lineno": 100,
          "context": "none",
          "resolved_location": "sklearn.metrics.r2_score"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_squared_error"
          ],
          "code_str": "mean_squared_error",
          "lineno": 101,
          "end_lineno": 101,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_squared_error"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 101,
          "end_lineno": 101,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "sklearn",
            "metrics",
            "mean_absolute_error"
          ],
          "code_str": "mean_absolute_error",
          "lineno": 102,
          "end_lineno": 102,
          "context": "none",
          "resolved_location": "sklearn.metrics.mean_absolute_error"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 108,
          "end_lineno": 108,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 109,
          "end_lineno": 109,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "array"
          ],
          "code_str": "np.array",
          "lineno": 110,
          "end_lineno": 110,
          "context": "none",
          "resolved_location": "numpy.array"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 112,
          "end_lineno": 112,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 112,
          "end_lineno": 112,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 112,
          "end_lineno": 112,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 112,
          "end_lineno": 112,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 112,
          "end_lineno": 112,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 113,
          "end_lineno": 113,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 113,
          "end_lineno": 113,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 113,
          "end_lineno": 113,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 113,
          "end_lineno": 113,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 113,
          "end_lineno": 113,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 114,
          "end_lineno": 114,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 114,
          "end_lineno": 114,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 114,
          "end_lineno": 114,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "sqrt"
          ],
          "code_str": "np.sqrt",
          "lineno": 114,
          "end_lineno": 114,
          "context": "none",
          "resolved_location": "numpy.sqrt"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 114,
          "end_lineno": 114,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 119,
          "end_lineno": 119,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "numpy",
            "mean"
          ],
          "code_str": "np.mean",
          "lineno": 123,
          "end_lineno": 123,
          "context": "none",
          "resolved_location": "numpy.mean"
        },
        {
          "import_components": [
            "numpy",
            "std"
          ],
          "code_str": "np.std",
          "lineno": 124,
          "end_lineno": 124,
          "context": "none",
          "resolved_location": "numpy.std"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 126,
          "end_lineno": 126,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "numpy",
            "flip"
          ],
          "code_str": "np.flip",
          "lineno": 127,
          "end_lineno": 127,
          "context": "none",
          "resolved_location": "numpy.flip"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 134,
          "end_lineno": 134,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "fill_between"
          ],
          "code_str": "plt.fill_between",
          "lineno": 135,
          "end_lineno": 135,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.fill_between"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 136,
          "end_lineno": 136,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 137,
          "end_lineno": 137,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 138,
          "end_lineno": 138,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylim"
          ],
          "code_str": "plt.ylim",
          "lineno": 138,
          "end_lineno": 138,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylim"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 139,
          "end_lineno": 139,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 139,
          "end_lineno": 139,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlim"
          ],
          "code_str": "plt.xlim",
          "lineno": 139,
          "end_lineno": 139,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlim"
        },
        {
          "import_components": [
            "numpy",
            "max"
          ],
          "code_str": "np.max",
          "lineno": 140,
          "end_lineno": 140,
          "context": "none",
          "resolved_location": "numpy.max"
        },
        {
          "import_components": [
            "numpy",
            "arange"
          ],
          "code_str": "np.arange",
          "lineno": 140,
          "end_lineno": 140,
          "context": "none",
          "resolved_location": "numpy.arange"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "yticks"
          ],
          "code_str": "plt.yticks",
          "lineno": 140,
          "end_lineno": 140,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.yticks"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 141,
          "end_lineno": 141,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "notebooks/sparse_gp_regression_for_big_molecular_data",
        "ref_id": "Model-Evaluation",
        "headings": [
          "Sparse GP Regression on Molecules",
          "Model Evaluation"
        ]
      },
      "doc_lineno": null
    },
    {
      "source": "rmse_mordred, mae_mordred = evaluate_model(X_mordred, y)",
      "names": [],
      "example": {
        "document": "notebooks/sparse_gp_regression_for_big_molecular_data",
        "ref_id": "Model-Evaluation",
        "headings": [
          "Sparse GP Regression on Molecules",
          "Model Evaluation"
        ]
      },
      "doc_lineno": null
    }
  ],
  "notebooks/wl_graph_kernel": [
    {
      "source": "%%capture\n# Imports\n\n# To import from the gauche package\nimport sys\nsys.path.append('..')\nsys.path.append('../benchmarks/')\n\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nimport torch, torch_geometric\n\nfrom gauche.dataloader import DataLoaderMP\nfrom gauche.dataloader.data_utils import transform_data\nfrom gpytorch_metrics import negative_log_predictive_density, mean_standardized_log_loss, quantile_coverage_error\n\nimport gpytorch\nfrom botorch import fit_gpytorch_model\nfrom rdkit.Chem import MolFromSmiles\n\nimport scipy.sparse as sp\nfrom functools import lru_cache\nimport warnings\n\nwarnings.filterwarnings(action='ignore', category=UserWarning, module=r'gpytorch')\nwarnings.filterwarnings(action='ignore', category=gpytorch.utils.warnings.NumericalWarning, module=r'gpytorch')",
      "names": [],
      "example": {
        "document": "notebooks/wl_graph_kernel",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "class WLFeatureFunction(torch.nn.Module):\n    def __init__(self, n_iter):\n        super().__init__()\n        self.convs = torch.nn.ModuleList([\n            torch_geometric.nn.WLConv() for _ in range(n_iter)])\n\n    def forward(self, graphs):\n        x = graphs.x  # node_labels_one_hot\n        edges = graphs.edge_index\n        idx = graphs.batch\n\n        hists = []\n        for conv in self.convs:\n            x = conv(x, edges)\n            hists.append(conv.histogram(x, idx, norm=False))\n\n        hists = torch.cat(hists, axis=1).float()\n        return torch.nn.functional.normalize(hists, dim=1)\n\nclass GraphDataset(torch.utils.data.Dataset):\n    def __init__(self, dataset_name, data_loc):\n        super().__init__()\n        self.loader = DataLoaderMP()\n        self.loader.load_benchmark(dataset_name, data_loc)\n        self.y = self.loader.labels\n\n    def __getitem__(self, idx):\n        mol = MolFromSmiles(self.loader.features[idx])\n\n        node_labels = np.array([\n            mol.GetAtomWithIdx(i).GetSymbol() \\\n            for i in range(mol.GetNumAtoms()) \\\n        ], dtype=str)\n\n        edges = []\n        for bond in mol.GetBonds():\n            start_idx = bond.GetBeginAtomIdx()\n            end_idx = bond.GetEndAtomIdx()\n            bond_type = bond.GetBondTypeAsDouble()\n\n            edges.append((start_idx, end_idx))\n            edges.append((end_idx, start_idx))\n\n        if len(node_labels) == 1: edges = [(0, 0)]\n\n        return torch_geometric.data.Data(\n                    x=node_labels,\n                    edge_index=torch.tensor(np.vstack(edges).T),\n                )\n\n    def __len__(self):\n        return len(self.y)\n\nclass GraphGP(gpytorch.models.ExactGP):\n    def __init__(self, train_x, train_y, likelihood):\n        super().__init__(train_x, train_y, likelihood)\n        self.mean = gpytorch.means.ConstantMean()\n        self.covariance = gpytorch.kernels.LinearKernel(len(train_x.T))\n        self.covariance.offset.requires_grad_(False)\n\n    def forward(self, x):\n        mean = self.mean(torch.zeros(len(x.data), 1)).float()\n        covariance = self.covariance(x)\n        return gpytorch.distributions.MultivariateNormal(mean, covariance)",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 22,
          "end_lineno": 22,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "str"
          ],
          "code_str": "str",
          "lineno": 33,
          "end_lineno": 33,
          "context": "none",
          "resolved_location": "str"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 44,
          "end_lineno": 44,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 52,
          "end_lineno": 52,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 56,
          "end_lineno": 56,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 58,
          "end_lineno": 58,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 62,
          "end_lineno": 62,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "notebooks/wl_graph_kernel",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    },
    {
      "source": "datasets = {\n    'Photoswitch': '../data/property_prediction/photoswitches.csv',\n    'ESOL': '../data/property_prediction/ESOL.csv',\n    'FreeSolv': '../data/property_prediction/FreeSolv.csv',\n    'Lipophilicity': '../data/property_prediction/Lipophilicity.csv'\n}\n\nn_trials, test_set_size = 20, 0.2\n\nfor dataset_name, data_loc in datasets.items():\n\n    data = GraphDataset(dataset_name, data_loc)\n    y = data.y\n\n    data = next(iter(torch_geometric.loader.DataLoader(data, batch_size=len(data), shuffle=False)))\n\n    node_labels = np.hstack(data.x).reshape(-1, 1)\n    node_labels = OneHotEncoder().fit_transform(node_labels)\n    node_labels = torch.tensor(node_labels.toarray()).float()\n    data.x = node_labels\n\n    X = WLFeatureFunction(n_iter=3)(data).numpy()\n\n    print(dataset_name); print('-'*50)\n    r2_list = []; rmse_list = []; mae_list = []; nlpd_list = []; msll_list = []; qce_list = []\n    for i in range(0, n_trials):\n        np.random.seed(i); torch.manual_seed(i)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, random_state=i)\n\n        #  We standardise the outputs but leave the inputs unchanged\n        # this seems to introduce numerical instabilities\n        _, y_train, _, y_test, y_scaler = transform_data(\n            np.zeros_like(y_train), y_train, np.zeros_like(y_test), y_test)\n\n        y_train = torch.tensor(y_train).flatten().float()\n        y_test = torch.tensor(y_test).flatten().float()\n\n        X_train = torch.tensor(X_train).float()\n        X_test = torch.tensor(X_test).float()\n\n        # initialise GP likelihood and model\n        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n        model = GraphGP(X_train, y_train, likelihood)\n\n        # Find optimal model hyperparameters\n        model.train()\n        likelihood.train()\n\n        # \"Loss\" for GPs - the marginal log likelihood\n        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n\n        # Use the BoTorch utility for fitting GPs in order to use the LBFGS-B optimiser (recommended)\n        # fit_gpytorch_model(mll)\n\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.5)  # Includes GaussianLikelihood parameters\n\n        for _ in range(150):\n            optimizer.zero_grad()\n            output = model(X_train)\n            loss = -mll(output, y_train)\n            loss.backward()\n            optimizer.step()\n        # print('Training successful')\n\n        # Get into evaluation (predictive posterior) mode\n        model.eval()\n        likelihood.eval()\n\n        # full GP predictive distribution\n        trained_pred_dist = likelihood(model(X_test))\n\n        # Compute NLPD on the Test set\n        try:\n            nlpd = negative_log_predictive_density(trained_pred_dist, y_test)\n        except:\n            with gpytorch.settings.cholesky_jitter(1e-1):\n                nlpd = negative_log_predictive_density(trained_pred_dist, y_test)\n\n        # Compute MSLL on Test set\n        msll = mean_standardized_log_loss(trained_pred_dist, y_test)\n\n        # Compute quantile coverage error on test set\n        qce = quantile_coverage_error(trained_pred_dist, y_test, quantile=95)\n\n        # mean and variance GP prediction\n        f_pred = model(X_test)\n\n        y_pred = f_pred.mean\n\n        # Transform back to real data space to compute metrics and detach gradients\n        y_pred = y_scaler.inverse_transform(y_pred.detach().unsqueeze(dim=1))\n        y_test = y_scaler.inverse_transform(y_test.detach().unsqueeze(dim=1))\n\n        # Output Standardised RMSE and RMSE on Train Set\n        y_train = y_train.detach()\n        y_pred_train = model(X_train).mean.detach()\n        train_rmse_stan = np.sqrt(mean_squared_error(y_train, y_pred_train))\n        train_rmse = np.sqrt(\n            mean_squared_error(y_scaler.inverse_transform(y_train.unsqueeze(dim=1)),\n                                y_scaler.inverse_transform(y_pred_train.unsqueeze(dim=1))))\n\n        # Compute R^2, RMSE and MAE on Test set\n        score = r2_score(y_test, y_pred)\n        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n        mae = mean_absolute_error(y_test, y_pred)\n\n        nlpd_list.append(nlpd)\n        msll_list.append(msll)\n        qce_list.append(qce)\n\n        r2_list.append(score)\n        rmse_list.append(rmse)\n        mae_list.append(mae)\n\n    nlpd_list = torch.tensor(nlpd_list)\n    msll_list = torch.tensor(msll_list)\n    qce_list = torch.tensor(qce_list)\n\n    r2_list = np.array(r2_list)\n    rmse_list = np.array(rmse_list)\n    mae_list = np.array(mae_list)\n\n    print(\"\\nmean NLPD: {:.4f} +- {:.4f}\".format(torch.mean(nlpd_list), torch.std(nlpd_list) / torch.sqrt(torch.tensor(n_trials))))\n    print(\"mean MSLL: {:.4f} +- {:.4f}\".format(torch.mean(msll_list), torch.std(msll_list) / np.sqrt(torch.tensor(n_trials))))\n    print(\"mean QCE: {:.4f} +- {:.4f}\".format(torch.mean(qce_list), torch.std(qce_list) / np.sqrt(torch.tensor(n_trials))))\n\n    print(\"mean R^2: {:.4f} +- {:.4f}\".format(np.mean(r2_list), np.std(r2_list) / np.sqrt(len(r2_list))))\n    print(\"mean RMSE: {:.4f} +- {:.4f}\".format(np.mean(rmse_list), np.std(rmse_list) / np.sqrt(len(rmse_list))))\n    print(\"mean MAE: {:.4f} +- {:.4f}\\n\".format(np.mean(mae_list), np.std(mae_list) / np.sqrt(len(mae_list))))",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "iter"
          ],
          "code_str": "iter",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "iter"
        },
        {
          "import_components": [
            "next"
          ],
          "code_str": "next",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "next"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 24,
          "end_lineno": 24,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 57,
          "end_lineno": 57,
          "context": "none",
          "resolved_location": "range"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 123,
          "end_lineno": 123,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 124,
          "end_lineno": 124,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 125,
          "end_lineno": 125,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 127,
          "end_lineno": 127,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 127,
          "end_lineno": 127,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 128,
          "end_lineno": 128,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 128,
          "end_lineno": 128,
          "context": "none",
          "resolved_location": "print"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 129,
          "end_lineno": 129,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 129,
          "end_lineno": 129,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "notebooks/wl_graph_kernel",
        "ref_id": null,
        "headings": []
      },
      "doc_lineno": null
    }
  ],
  "readme": []
}